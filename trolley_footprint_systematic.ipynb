{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "import gm2\n",
    "import trfp\n",
    "import plotting_functions as plt2\n",
    "import analysis_helper as helper\n",
    "import helper_function_candidates as helper_old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data from 60 hr trolley run and fixed probe run\n",
    "\n",
    "filename = 'hdf5/60hr.h5'\n",
    "\n",
    "tr_interp_df_1 = pd.read_hdf(filename, key='tr_df_1')\n",
    "fp_interp_df_1 = pd.read_hdf(filename, key='fp_df_1')\n",
    "tr_interp_df_2 = pd.read_hdf(filename, key='tr_df_2')\n",
    "\n",
    "tr_moment_df_1 = helper.calc_moment_df(tr_interp_df_1)\n",
    "tr_moment_df_2 = helper.calc_moment_df(tr_interp_df_2)\n",
    "fp_moment_df_1 = helper.calc_moment_df(fp_interp_df_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at length of tr runs, pick random starting point in fixed probe run to call fake trolley\n",
    "\n",
    "## trolley moment dfs are 4300-4400 seconds long\n",
    "\n",
    "duration = np.random.randint(4300,4401)\n",
    "start = np.random.randint(0, fp_moment_df_1.shape[0]-duration)\n",
    "\n",
    "fake_tr_run = fp_moment_df_1.iloc[start:start+duration].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trolley runs start at 262.2 deg and end at 262.7 deg\n",
    "\n",
    "tr_phi = (np.linspace(262.2, 262.7+360, duration) + np.random.uniform(-0.03,0.03,))%360\n",
    "fake_tr_run['tr_phi'] = tr_phi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_mask_df = fake_tr_run.copy()\n",
    "t0 = no_mask_df.index.values[0]\n",
    "no_mask_df.index -= t0\n",
    "index = no_mask_df.index.values\n",
    "\n",
    "veto_extent = 25\n",
    "\n",
    "for st in [20]:  # range(72):\n",
    "    print '\\rRemoving trolley image from station '+str(st)+'.',\n",
    "\n",
    "    # veto when trolley is close to station\n",
    "\n",
    "    veto_low = (trfp.STATION_BARCODE_PHI[st]-1.5-veto_extent/2)%360\n",
    "    veto_high = (trfp.STATION_BARCODE_PHI[st]-1.5+veto_extent/2)%360\n",
    "    if veto_low < veto_high:\n",
    "        veto_mask = (no_mask_df['tr_phi']>veto_low) & (no_mask_df['tr_phi']<veto_high)\n",
    "    else:  # this happens when wrapping around 360 deg\n",
    "        veto_mask = (no_mask_df['tr_phi']>veto_low) | (no_mask_df['tr_phi']<veto_high)\n",
    "\n",
    "    for m in [0]:  #range(6):\n",
    "\n",
    "        stm = 'st'+str(st)+',m'+str(m+1)\n",
    "\n",
    "        # calculate local drift\n",
    "\n",
    "        times = no_mask_df.index.values[~veto_mask]\n",
    "        freqs = no_mask_df[stm][~veto_mask]\n",
    "\n",
    "        local_drift_fit = np.polyfit(times, freqs, 5)\n",
    "        local_drift = np.polyval(local_drift_fit, no_mask_df.index.values)\n",
    "\n",
    "        # need to average other side of ring\n",
    "        all_good_stations = np.arange(6,72)  # not using the inflector stations\n",
    "        no_ground_loop_stations = np.array(range(6,16)+range(64,72))  # vaid for 25 deg veto\n",
    "\n",
    "        # next need to average all good stations that are not within 3 of current station\n",
    "        if st not in range(16, 23):  # note that these ranged were chosen for 25 deg veto\n",
    "            averaging_stations = np.delete(all_good_stations,\n",
    "                                           np.argwhere((np.abs((all_good_stations - st)%72)<=3)\n",
    "                                                      | (np.abs((all_good_stations - st)%72)>=69))\n",
    "                                          )\n",
    "        else:\n",
    "            averaging_stations = np.delete(no_ground_loop_stations,\n",
    "                                           np.argwhere((np.abs((no_ground_loop_stations - st)%72)<=3)\n",
    "                                                      | (np.abs((no_ground_loop_stations - st)%72)>=69))\n",
    "                                          )\n",
    "        avg_stms = ['st'+str(avg_st)+',m'+str(m+1) for avg_st in averaging_stations]\n",
    "        replacement = no_mask_df[avg_stms].mean(axis=1)\n",
    "\n",
    "        # calculate global drift\n",
    "        global_drift_fit = np.polyfit(index[veto_mask], replacement[veto_mask], 1)\n",
    "        global_drift = np.polyval(global_drift_fit, index[veto_mask])\n",
    "\n",
    "        # subtract global drift from replacement\n",
    "        replacement = replacement[veto_mask] - global_drift\n",
    "\n",
    "        # add local drift\n",
    "        replacement = replacement + local_drift[veto_mask]\n",
    "\n",
    "        no_mask_df[stm][veto_mask] = replacement\n",
    "\n",
    "no_mask_df.index += t0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if veto_low < veto_high:\n",
    "    veto_mask = (no_mask_df['tr_phi']>veto_low) & (no_mask_df['tr_phi']<veto_high)\n",
    "else:  # this happens when wrapping around 360 deg\n",
    "    veto_mask = (no_mask_df['tr_phi']>veto_low) | (no_mask_df['tr_phi']<veto_high)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig1, ax1 = plt.subplots(2,1)\n",
    "\n",
    "ax1[0].plot(fake_tr_run.index.values[~veto_mask]-t0, fake_tr_run['st20,m1'][~veto_mask], '.')\n",
    "ax1[0].plot(fake_tr_run.index.values[veto_mask]-t0, fake_tr_run['st20,m1'][veto_mask], '.', label='veto region')\n",
    "ax1[1].plot(no_mask_df.index.values[~veto_mask]-t0, no_mask_df['st20,m1'][~veto_mask], '.')\n",
    "ax1[1].plot(no_mask_df.index.values[veto_mask]-t0, no_mask_df['st20,m1'][veto_mask], '.', label='veto region')\n",
    "\n",
    "for ax in ax1:\n",
    "    ax.set_xlabel('time (sec)', fontdict={'size':12, 'family':'serif'})\n",
    "    ax.set_ylabel('freq - 61.79 Mhz (Hz)', fontdict={'size':12, 'family':'serif'})\n",
    "    ax.legend(prop={'size':10, 'family':'serif'})\n",
    "\n",
    "ax1[0].set_title('True Data', fontdict={'size':12, 'family':'serif'})\n",
    "ax1[1].set_title('Replaced Data', fontdict={'size':12, 'family':'serif'})\n",
    "\n",
    "fig1.set_size_inches(6,6)\n",
    "fig1.tight_layout()\n",
    "\n",
    "fig1.savefig('replacement_syst_demo.png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt2.plt_unix_time_to_CST(ax1[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## find averages\n",
    "\n",
    "def trolley_run_station_average(corrected_df):\n",
    "        \n",
    "    station_edges = trfp.STATION_BARCODE_EDGES\n",
    "    station_edges_6_probe = trfp.STATION_BARCODE_EDGES_6\n",
    "\n",
    "    # tr_phi is not monotonic, so sort by tr_phi\n",
    "\n",
    "    corrected_df = corrected_df.sort_values(by=['tr_phi'])\n",
    "\n",
    "    measured_phi = corrected_df['tr_phi'].values\n",
    "    measured_extent = (np.roll(measured_phi,-1)-np.roll(measured_phi,1))/2\n",
    "    measured_extent[0] = measured_extent[0]+180\n",
    "    measured_extent[-1] = measured_extent[-1]+180\n",
    "    # print np.max(measured_extent)\n",
    "\n",
    "    corrected_df['tr_extent'] = pd.Series(measured_extent, index=corrected_df.index)\n",
    "    corrected_df = corrected_df.sort_index()\n",
    "\n",
    "    # for a given station:\n",
    "    # create a mask for when trolley is in [low edge, high edge)\n",
    "    tr_baseline = np.full((72,6), np.nan)\n",
    "    fp_baseline = np.full((72,6), np.nan)\n",
    "    summed_azimuth = np.full((72,6), np.nan)\n",
    "    summed_pts = np.full((72,6), np.nan)\n",
    "    baseline_time = np.full((72,6), np.nan)\n",
    "\n",
    "    st6 = 0\n",
    "    for st in range(72):\n",
    "        \n",
    "        num_probes = len(trfp.STATION_PROBE_ID[st])\n",
    "        # first do m1-4 for all stations\n",
    "        \n",
    "        if station_edges[st+1] > station_edges[st]:\n",
    "            mask = (corrected_df['tr_phi'] >= station_edges[st]) & (corrected_df['tr_phi'] < station_edges[st+1])\n",
    "        else:  # case where we go over the 360 deg line\n",
    "            mask = (corrected_df['tr_phi'] >= station_edges[st]) | (corrected_df['tr_phi'] < station_edges[st+1])\n",
    "\n",
    "        out_df = corrected_df[mask].copy()\n",
    "        summed_pts[st, :] = out_df.shape[0]\n",
    "        summed_azimuth[st, :] = sum(out_df['tr_extent'].values)\n",
    "        baseline_time[st, :] = sum(out_df.index.values)/summed_pts[st, 0]\n",
    "\n",
    "        for m in range(6):\n",
    "\n",
    "            st_id = 'st'+str(st)+',m'+str(m+1)\n",
    "            if sum(out_df['tr_extent'].values) != 0:\n",
    "                fp_baseline[st, m] = np.mean(out_df[st_id])\n",
    "                \n",
    "    return tr_baseline, fp_baseline, baseline_time, summed_azimuth, summed_pts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, fake_fp_baseline, _, _, _ = trolley_run_station_average(no_mask_df)\n",
    "_, real_fp_baseline, _, _, _ = trolley_run_station_average(fake_tr_run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print fake_fp_baseline.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print fake_fp_baseline[20,0]\n",
    "print real_fp_baseline[20,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## automate the above and compare all stations many time to histogram the uncertainty\n",
    "\n",
    "def footprint_replacment(fake_tr_run):\n",
    "    no_mask_df = fake_tr_run.copy()\n",
    "    t0 = no_mask_df.index.values[0]\n",
    "    no_mask_df.index -= t0\n",
    "    index = no_mask_df.index.values\n",
    "\n",
    "    veto_extent = 25\n",
    "\n",
    "    for st in range(72):\n",
    "        print '\\rRemoving trolley image from station '+str(st)+'.',\n",
    "\n",
    "        # veto when trolley is close to station\n",
    "\n",
    "        veto_low = (trfp.STATION_BARCODE_PHI[st]-1.5-veto_extent/2)%360\n",
    "        veto_high = (trfp.STATION_BARCODE_PHI[st]-1.5+veto_extent/2)%360\n",
    "        if veto_low < veto_high:\n",
    "            veto_mask = (no_mask_df['tr_phi']>veto_low) & (no_mask_df['tr_phi']<veto_high)\n",
    "        else:  # this happens when wrapping around 360 deg\n",
    "            veto_mask = (no_mask_df['tr_phi']>veto_low) | (no_mask_df['tr_phi']<veto_high)\n",
    "\n",
    "        for m in range(6):\n",
    "\n",
    "            stm = 'st'+str(st)+',m'+str(m+1)\n",
    "\n",
    "            # calculate local drift\n",
    "\n",
    "            times = no_mask_df.index.values[~veto_mask]\n",
    "            freqs = no_mask_df[stm][~veto_mask]\n",
    "\n",
    "            local_drift_fit = np.polyfit(times, freqs, 5)\n",
    "            local_drift = np.polyval(local_drift_fit, no_mask_df.index.values)\n",
    "\n",
    "            # need to average other side of ring\n",
    "            all_good_stations = np.arange(6,72)  # not using the inflector stations\n",
    "            no_ground_loop_stations = np.array(range(6,16)+range(64,72))  # vaid for 25 deg veto\n",
    "\n",
    "            # next need to average all good stations that are not within 3 of current station\n",
    "            if st not in range(16, 23):  # note that these ranged were chosen for 25 deg veto\n",
    "                averaging_stations = np.delete(all_good_stations,\n",
    "                                               np.argwhere((np.abs((all_good_stations - st)%72)<=3)\n",
    "                                                          | (np.abs((all_good_stations - st)%72)>=69))\n",
    "                                              )\n",
    "            else:\n",
    "                averaging_stations = np.delete(no_ground_loop_stations,\n",
    "                                               np.argwhere((np.abs((no_ground_loop_stations - st)%72)<=3)\n",
    "                                                          | (np.abs((no_ground_loop_stations - st)%72)>=69))\n",
    "                                              )\n",
    "            avg_stms = ['st'+str(avg_st)+',m'+str(m+1) for avg_st in averaging_stations]\n",
    "            replacement = no_mask_df[avg_stms].mean(axis=1)\n",
    "\n",
    "            # calculate global drift\n",
    "            global_drift_fit = np.polyfit(index[veto_mask], replacement[veto_mask], 1)\n",
    "            global_drift = np.polyval(global_drift_fit, index[veto_mask])\n",
    "\n",
    "            # subtract global drift from replacement\n",
    "            replacement = replacement[veto_mask] - global_drift\n",
    "\n",
    "            # add local drift\n",
    "            replacement = replacement + local_drift[veto_mask]\n",
    "\n",
    "            no_mask_df[stm][veto_mask] = replacement\n",
    "\n",
    "    no_mask_df.index += t0\n",
    "    return no_mask_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## in for loop, generate fake data set, average the replacement data and real data, and look at difference\n",
    "\n",
    "N = 50\n",
    "\n",
    "m_diffs = np.empty([72,6,N])\n",
    "\n",
    "for ii in range(N):\n",
    "    \n",
    "    print ii\n",
    "    \n",
    "    duration = np.random.randint(4300,4401)\n",
    "    start = np.random.randint(0, fp_moment_df_1.shape[0]-duration)\n",
    "    fake_tr_run = fp_moment_df_1.iloc[start:start+duration].copy()\n",
    "    tr_phi = (np.linspace(262.2, 262.7+360, duration) + np.random.uniform(-0.03,0.03,))%360\n",
    "    fake_tr_run['tr_phi'] = tr_phi\n",
    "    \n",
    "    fake_replaced = footprint_replacment(fake_tr_run)\n",
    "    \n",
    "    _, replaced_fp_baseline, _, _, _ = trolley_run_station_average(fake_replaced)\n",
    "    _, real_fp_baseline, _, _, _ = trolley_run_station_average(fake_tr_run)\n",
    "    \n",
    "    m_diffs[:,:,ii] = replaced_fp_baseline - real_fp_baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m1_diffs = m_diffs[:,0,:].flatten()\n",
    "\n",
    "def gaussian(x, A, x0, s): return A * np.exp(-(x-x0)**2/(2*s**2))\n",
    "\n",
    "fig2, ax2 = plt.subplots(1,1)\n",
    "\n",
    "out = ax2.hist(m1_diffs, bins=500)\n",
    "counts = out[0]\n",
    "bins = (out[1][1:]+out[1][:-1])/2\n",
    "\n",
    "fit, _ = curve_fit(gaussian, bins, counts)\n",
    "\n",
    "ax2.plot(np.linspace(-25,25,1000), gaussian(np.linspace(-25,25,1000), *fit),\n",
    "         label=('$\\mu$ = %.1e \\n $\\sigma$ = %.1e'%(fit[1],fit[2])))\n",
    "ax2.set_xlim(-10,10)\n",
    "ax2.legend(prop={'size':10, 'family':'serif'})\n",
    "\n",
    "ax2.set_title('$m_1$ Footprint Replacement Error', fontdict={'size':12, 'family':'serif'})\n",
    "ax2.set_xlabel('footprint replacement error (Hz)', fontdict={'size':12, 'family':'serif'})\n",
    "ax2.set_ylabel('counts', fontdict={'size':12, 'family':'serif'})\n",
    "\n",
    "fig2.set_size_inches(6,4)\n",
    "fig2.tight_layout()\n",
    "\n",
    "print fit\n",
    "\n",
    "fig2.savefig('replacement_m1_hist.png', dpi=300)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig3, ax3 = plt.subplots(2,2)\n",
    "\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        m = 2*i + j\n",
    "        diffs = m_diffs[:,m+1,:].flatten()\n",
    "        \n",
    "        out = ax3[i,j].hist(diffs, bins=np.linspace(-10,10, 60))\n",
    "        counts = out[0]\n",
    "        bins = (out[1][1:]+out[1][:-1])/2\n",
    "\n",
    "        fit, _ = curve_fit(gaussian, bins, counts)\n",
    "\n",
    "        ax3[i,j].plot(np.linspace(-25,25,1000), gaussian(np.linspace(-25,25,1000), *fit))\n",
    "        ax3[i,j].set_title(('$\\mu$ = %.1e \\n $\\sigma$ = %.1e'%(fit[1],np.abs(fit[2]))), fontdict={'size':10, 'family':'serif'})\n",
    "        ax3[i,j].set_xlim(-3,3)\n",
    "        ax3[i,j].set_xlabel('footprint replacement error (Hz)', fontdict={'size':10, 'family':'serif'})\n",
    "        ax3[i,j].set_ylabel('$m_'+str(m+2)+'$', fontdict={'size':12, 'family':'serif'})\n",
    "\n",
    "fig3.set_size_inches(6,5)\n",
    "fig3.tight_layout()\n",
    "\n",
    "fig3.savefig('replacement_m2-5_hist.png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diffs = m_diffs[:,1,:].flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = plt.hist(diffs, bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
