{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to JupyROOT 6.22/02\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from scipy.optimize import curve_fit\n",
    "from scipy.interpolate import interp1d\n",
    "\n",
    "import gm2\n",
    "import trfp\n",
    "import plotting_functions as plt2\n",
    "import helper_functions as helper\n",
    "\n",
    "import field_map_config_run1 as map_config\n",
    "import muon_dist_config_run1 as dist_config\n",
    "\n",
    "rates = np.array([0.0002440148957033999, 7.174497059079315e-06, 5.597953677893461e-06,\n",
    "                  2.471179896215746e-06, 2.469063223225018e-05, 4.98031484960896e-07,\n",
    "                  2.3557763230871967e-06, 1.3267701986068543e-06, 2.733157063334935e-06])\n",
    "                  ## 27 Jan, `sync_offset_studies`, uses station-by-station widths and correlation matrix\n",
    "\n",
    "def parameterize_beam(beam, beam_x, beam_y):\n",
    "    x, y = np.meshgrid(beam_x, beam_y)\n",
    "\n",
    "    dx = np.mean(np.diff(beam_x))\n",
    "    dy = np.mean(np.diff(beam_y))\n",
    "\n",
    "    order = trfp.matrices._MULTIPOLE_ORDER\n",
    "    skew = trfp.matrices._MULTIPOLE_SKEW\n",
    "    multipole = trfp.matrices.__multipole\n",
    "\n",
    "    n = len(order)\n",
    "    k = np.zeros(n)\n",
    "\n",
    "    for i in range(n):\n",
    "        f = multipole(order[i], skew[i], 1, x, y)\n",
    "        k[i] = np.sum(f*beam*dx*dy)/np.sum(beam*dx*dy)\n",
    "    return k\n",
    "\n",
    "def cov(t1, t2, T, M=1):  # BB, units for M are Hz^2/sec\n",
    "    u = np.minimum(t1, t2)\n",
    "    v = np.maximum(t1, t2)\n",
    "    return M * (T - v) * u / T\n",
    "\n",
    "def cov2(t1, t2, T, M=1):  # RW, units for M are Hz^2/sec\n",
    "    u = np.minimum(t1, t2)\n",
    "    v = np.maximum(t1, t2)\n",
    "    return M * u\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['ctags', 'km_total', 'BB_total',\n",
    "           'k1', 'm1', 'km1', 'BB1',\n",
    "           'k2', 'm2', 'km2', 'BB2',\n",
    "           'k3', 'm3', 'km3', 'BB3',\n",
    "           'k4', 'm4', 'km4', 'BB4',\n",
    "           'k5', 'm5', 'km5', 'BB5',\n",
    "           'k6', 'm6', 'km6', 'BB6',\n",
    "           'k7', 'm7', 'km7', 'BB7',\n",
    "           'k8', 'm8', 'km8', 'BB8',\n",
    "           'k9', 'm9', 'km9', 'BB9']\n",
    "\n",
    "index = map_config.subruns\n",
    "# index = ['1a1']#, '1b2']#, '1d4', '1d5', '1d6']\n",
    "\n",
    "run_1_df = pd.DataFrame(0.0, index=index, columns=columns)\n",
    "\n",
    "data_file = '/data2/aetb/2021-02-17_hybrid_maps.h5'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Run 1a1\n",
      "Starting Run 1b1\n",
      "Starting Run 1b2\n",
      "Starting Run 1c1\n",
      "Starting Run 1c2\n",
      "Starting Run 1c3\n",
      "Starting Run 1d2\n",
      "Starting Run 1d3\n",
      "Starting Run 1d4\n",
      "Starting Run 1d5\n",
      "Starting Run 1d6\n",
      "CPU times: user 13min 2s, sys: 2min 6s, total: 15min 9s\n",
      "Wall time: 17min 52s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "for run in index:\n",
    "    \n",
    "    print 'Starting Run ' + run\n",
    "\n",
    "    key = 'run_'+run\n",
    "\n",
    "    vtm_df = pd.read_hdf(data_file, key=key)\n",
    "\n",
    "    config_dict = dist_config.config_dict\n",
    "    data_run = run\n",
    "\n",
    "    vtm_file = config_dict[data_run][0]\n",
    "    vtm_key = config_dict[data_run][1]\n",
    "    interp_file = config_dict[data_run][2]\n",
    "    interp_key_1 = config_dict[data_run][3]\n",
    "    interp_key_2 = config_dict[data_run][4]\n",
    "    gold_subruns_file = config_dict[data_run][5]\n",
    "    beam_files = config_dict[data_run][6]\n",
    "\n",
    "    tr_interp_df_1 = pd.read_hdf(interp_file, key=interp_key_1)\n",
    "    t_start = np.mean(tr_interp_df_1.index.values)\n",
    "    tr_interp_df_2 = pd.read_hdf(interp_file, key=interp_key_2)\n",
    "    if data_run == '1d6': t_end = np.inf  # deals with not having a closing trolley run for 1d6\n",
    "    else: t_end = np.mean(tr_interp_df_2.index.values)\n",
    "\n",
    "    # Import a gold subrun list\n",
    "\n",
    "    subrun_df = pd.read_hdf(interp_file, key='subrun_df')\n",
    "    gold_subruns = np.loadtxt(gold_subruns_file)\n",
    "    gold_subruns_df = pd.DataFrame(gold_subruns.astype(int), columns=['run', 'subrun']).merge(subrun_df, on=['run', 'subrun'])\n",
    "    gold_subruns_df = gold_subruns_df[(gold_subruns_df['start_gps']>=t_start) & (gold_subruns_df['end_gps']<=t_end)]\n",
    "    \n",
    "    # Aside: Do the RW/BB calculation here\n",
    "    ## a vector is number of ctags in each subrun divided by the number of ctags in all used subruns\n",
    "    a = gold_subruns_df['ctags'].values/float(gold_subruns_df['ctags'].sum())\n",
    "    ## make vector of subrun times after trolley run (use avg)\n",
    "    t_subrun = ((gold_subruns_df['start_gps']+gold_subruns_df['end_gps'])/2).values - t_start\n",
    "    t_period = t_end - t_start\n",
    "    ## build the covariance matrix sigma\n",
    "    ## t1, t2 are the two times under consideration, can be matrices\n",
    "    ## make t1 a matrix of proper size with time by row; t2 is by column; ~10 sec\n",
    "    t1 = np.outer(t_subrun, np.ones(t_subrun.size))\n",
    "    t2 = np.outer(np.ones(t_subrun.size), t_subrun)\n",
    "    ## run the cov function (note, this takes ~1 min)\n",
    "    if (run == '1d6'):\n",
    "        sigma = cov2(t1, t2, t_period, M=1)  # use M=1, scale with rates later to save time\n",
    "    else:\n",
    "        sigma = cov(t1, t2, t_period, M=1)\n",
    "    sigma_avg = np.dot(a, np.dot(sigma, a))\n",
    "\n",
    "    # need to bin into subruns\n",
    "\n",
    "    vtm_interp = interp1d(vtm_df.index, vtm_df.values, axis=0)\n",
    "    times = gold_subruns_df['start_gps'].append(gold_subruns_df['end_gps'])\n",
    "\n",
    "    boundary_df = pd.DataFrame(vtm_interp(times), index=times, columns=vtm_df.columns)\n",
    "\n",
    "    vtm_interp_df = vtm_df.append(boundary_df).sort_index()\n",
    "\n",
    "    boundary_cut = pd.IntervalIndex.from_arrays(gold_subruns_df['start_gps'], gold_subruns_df['end_gps'], closed='both')\n",
    "    vtm_cut = pd.cut(vtm_interp_df.index, boundary_cut)\n",
    "\n",
    "    def avg_technique(bin_):\n",
    "        numer = np.trapz(bin_, x=bin_.index.values, axis=0)\n",
    "        denom = np.max(bin_.index.values)-np.min(bin_.index.values)\n",
    "\n",
    "        return numer/denom\n",
    "\n",
    "    avg_field = vtm_interp_df.groupby(vtm_cut).apply(avg_technique)\n",
    "    avg_df = pd.DataFrame.from_dict(dict(zip(avg_field.index, avg_field.values)), orient='index', columns=vtm_df.columns)\n",
    "    avg_df['start_gps'] = [interval[0] for interval in avg_df.index.to_tuples().values]\n",
    "    avg_df['end_gps'] = [interval[1] for interval in avg_df.index.to_tuples().values]\n",
    "\n",
    "    output_df = gold_subruns_df[['run', 'subrun', 'start_gps', 'end_gps', 'ctags']].copy()\n",
    "    output_df = output_df.merge(avg_df, on=['start_gps', 'end_gps'])\n",
    "\n",
    "    output_columns = ['run', 'subrun', 'start_gps', 'end_gps', 'ctags'] + ['st'+str(st)+',m'+str(m+1) for st in range(72) for m in range(9)]\n",
    "    output_df = output_df[output_columns]\n",
    "\n",
    "    ###################################################\n",
    "    ## make a time varying, azimuthally varying profile\n",
    "    ###################################################\n",
    "\n",
    "    azi_run_k_df = pd.DataFrame()\n",
    "\n",
    "    for ii in range(len(beam_files)):\n",
    "\n",
    "        beam_filename = 'BeamSpot_'+str(beam_files[ii][0])+'_'+str(beam_files[ii][1])+'.root'\n",
    "\n",
    "        beam, beam_x, beam_y, phi = gm2.trfp.conv.loadBeamNew(beam_filename, path='/data1/newg2/Run1TrackerData/22Sep2020/', integrated=False)\n",
    "        phi = phi + 18.35\n",
    "        beam_x = beam_x/10\n",
    "        beam_y = beam_y/10\n",
    "        for hh in range(len(beam)):\n",
    "            beam[hh] = np.transpose(beam[hh])\n",
    "\n",
    "        k_azi = np.empty([14, 72])\n",
    "        for ll in range(72):\n",
    "            k_azi[:,ll] = parameterize_beam(beam[ll], beam_x, beam_y)\n",
    "\n",
    "        k_azi_interp = np.empty([14,72*3])\n",
    "        k_azi_interp[:,0:72] = k_azi\n",
    "        k_azi_interp[:,72:144] = k_azi\n",
    "        k_azi_interp[:,144:216] = k_azi\n",
    "\n",
    "        phi_interp = np.array([phi-360, phi, phi+360]).flatten()\n",
    "\n",
    "        k_interp = interp1d(phi_interp, k_azi_interp, axis=1, kind='cubic')\n",
    "\n",
    "        station_centers = (trfp.geometry.STATION_BARCODE_EDGES[:-1] + trfp.geometry.STATION_BARCODE_EDGES[1:])/2\n",
    "        station_centers[2] = station_centers[2] + 180\n",
    "\n",
    "        k_station = k_interp(station_centers)\n",
    "\n",
    "        run_range = np.arange(beam_files[ii][0], beam_files[ii][1]+1)\n",
    "\n",
    "        for jj in range(len(run_range)):\n",
    "            run_append_dict = {}\n",
    "            run_append_dict['run'] = run_range[jj]\n",
    "            for st in range(72):    \n",
    "                for kk in range(9):\n",
    "                    run_append_dict['st'+str(st)+',k'+str(kk+1)] = [k_station[kk,st]]\n",
    "            azi_run_k_df = azi_run_k_df.append(pd.DataFrame.from_dict(run_append_dict))\n",
    "\n",
    "    stk = ['st'+str(st)+',k'+str(k+1) for st in range(72) for k in range(9)]\n",
    "    azi_run_k_df = azi_run_k_df.set_index(azi_run_k_df['run'].values)\n",
    "    azi_run_k_df = azi_run_k_df[stk]\n",
    "\n",
    "    ## need to add in a run 15954 for Run 1a\n",
    "\n",
    "    if run == '1a1':\n",
    "        append_df = ((azi_run_k_df.loc[15953] + azi_run_k_df.loc[15955])/2)\n",
    "        append_df.name = 15954\n",
    "        azi_run_k_df = azi_run_k_df.append(append_df)\n",
    "        azi_run_k_df = azi_run_k_df.sort_index()\n",
    "\n",
    "    stkm = ['st'+str(st)+',km'+str(km+1) for st in range(72) for km in range(9)]\n",
    "    stk = ['st'+str(st)+',k'+str(k+1) for st in range(72) for k in range(9)]\n",
    "    stm = ['st'+str(st)+',m'+str(m+1) for st in range(72) for m in range(9)]\n",
    "\n",
    "    def subrun_bin(df):\n",
    "        stm = ['st'+str(st)+',m'+str(m+1) for st in range(72) for m in range(9)]\n",
    "\n",
    "        bin_df = pd.Series(index=['start_gps', 'end_gps', 'ctags']+stm)\n",
    "        bin_df['start_gps'] = df['start_gps'].min()\n",
    "        bin_df['end_gps'] = df['end_gps'].max()\n",
    "        bin_df['ctags'] = df['ctags'].sum()\n",
    "        bin_df[stm] = df['ctags'].dot(df[stm])/df['ctags'].sum()\n",
    "\n",
    "        return bin_df\n",
    "\n",
    "    bin_df = output_df.groupby('run').apply(subrun_bin)\n",
    "\n",
    "    run_df = (azi_run_k_df[stk].rename(columns=dict(zip(stk,stm))) * bin_df[stm]).dropna()\n",
    "    run_df = run_df.rename(columns=dict(zip(stm,stkm)))\n",
    "    run_df['start_gps'] = bin_df['start_gps']\n",
    "    run_df['end_gps'] = bin_df['end_gps']\n",
    "    run_df['ctags'] = bin_df['ctags']\n",
    "    run_df = run_df[['start_gps', 'end_gps', 'ctags']+stkm]\n",
    "\n",
    "    weight = (trfp.STATION_BARCODE_EDGES[1:] - trfp.STATION_BARCODE_EDGES[:-1])\n",
    "    weight[2] = (weight[2] + 360)\n",
    "    weight = weight/360\n",
    "\n",
    "    run_sum = run_df['ctags'].dot(run_df[stkm])/run_df['ctags'].sum()\n",
    "\n",
    "    run_km = np.empty(9)\n",
    "    for km in range(9):\n",
    "        _stkm = ['st'+str(st)+',km'+str(km+1) for st in range(72)]\n",
    "        run_km[km] = run_sum[_stkm].multiply(weight).sum()\n",
    "\n",
    "\n",
    "    # print np.round(run_km[0], decimals=5)\n",
    "    # print np.round(run_km[1], decimals=5)\n",
    "    # print np.round(run_km[2], decimals=5)\n",
    "    # print np.round(run_km[3], decimals=5)\n",
    "    # print np.round(run_km[4], decimals=5)\n",
    "    # print\n",
    "    # print np.round(np.sum(run_km), decimals=5)\n",
    "\n",
    "    for m in range(9):\n",
    "\n",
    "        # get azi and time averaged m values\n",
    "        stm_list = ['st'+str(st)+',m'+str(m+1) for st in np.arange(72)]\n",
    "        bin_df['m'+str(m+1)] = bin_df[stm_list].multiply(weight).sum(axis=1)\n",
    "        run_1_df['m'+str(m+1)].loc[run] = (bin_df['ctags']*bin_df['m'+str(m+1)]).sum()/bin_df['ctags'].sum()\n",
    "\n",
    "        stk_list = ['st'+str(st)+',k'+str(m+1) for st in np.arange(72)]\n",
    "        azi_run_k_df['k'+str(m+1)] = azi_run_k_df[stk_list].multiply(weight).sum(axis=1)\n",
    "        run_1_df['k'+str(m+1)].loc[run] = (bin_df['ctags']*azi_run_k_df['k'+str(m+1)]).sum()/bin_df['ctags'].sum()\n",
    "\n",
    "        stkm_list = ['st'+str(st)+',km'+str(m+1) for st in np.arange(72)]\n",
    "        run_df['km'+str(m+1)] = run_df[stkm_list].multiply(weight).sum(axis=1)\n",
    "        run_1_df['km'+str(m+1)].loc[run] = (run_df['ctags']*run_df['km'+str(m+1)]).sum()/run_df['ctags'].sum()\n",
    "        \n",
    "        # scale RW/BB uncertainties by rate, put in output df\n",
    "        run_1_df['BB'+str(m+1)].loc[run] = np.sqrt(sigma_avg*rates[m])\n",
    "\n",
    "    run_1_df['ctags'].loc[run] = run_df['ctags'].sum()\n",
    "    run_1_df['km_total'].loc[run] = run_1_df[['km'+str(km+1) for km in range(9)]].loc[run].sum()\n",
    "    run_1_df['BB_total'].loc[run] = np.sqrt(np.dot(run_1_df[['k'+str(m+1) for m in range(9)]].loc[run].values**2,\n",
    "                                                   run_1_df[['BB'+str(m+1) for m in range(9)]].loc[run].values**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_1_df.to_csv('run_1_df_2021-02-17.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ctags</th>\n",
       "      <th>km_total</th>\n",
       "      <th>BB_total</th>\n",
       "      <th>k1</th>\n",
       "      <th>m1</th>\n",
       "      <th>km1</th>\n",
       "      <th>BB1</th>\n",
       "      <th>k2</th>\n",
       "      <th>m2</th>\n",
       "      <th>km2</th>\n",
       "      <th>...</th>\n",
       "      <th>km7</th>\n",
       "      <th>BB7</th>\n",
       "      <th>k8</th>\n",
       "      <th>m8</th>\n",
       "      <th>km8</th>\n",
       "      <th>BB8</th>\n",
       "      <th>k9</th>\n",
       "      <th>m9</th>\n",
       "      <th>km9</th>\n",
       "      <th>BB9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1a1</th>\n",
       "      <td>485123992.0</td>\n",
       "      <td>51874.698930</td>\n",
       "      <td>2.631486</td>\n",
       "      <td>1.0</td>\n",
       "      <td>51881.842153</td>\n",
       "      <td>51881.842153</td>\n",
       "      <td>2.629353</td>\n",
       "      <td>0.150495</td>\n",
       "      <td>-4.464607</td>\n",
       "      <td>-0.218858</td>\n",
       "      <td>...</td>\n",
       "      <td>0.043441</td>\n",
       "      <td>0.258350</td>\n",
       "      <td>0.000073</td>\n",
       "      <td>3.676687</td>\n",
       "      <td>-0.031824</td>\n",
       "      <td>0.193882</td>\n",
       "      <td>-0.000274</td>\n",
       "      <td>-83.728230</td>\n",
       "      <td>0.018608</td>\n",
       "      <td>0.278274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1b1</th>\n",
       "      <td>562216478.0</td>\n",
       "      <td>51944.382182</td>\n",
       "      <td>2.453179</td>\n",
       "      <td>1.0</td>\n",
       "      <td>51952.245993</td>\n",
       "      <td>51952.245993</td>\n",
       "      <td>2.451712</td>\n",
       "      <td>0.132500</td>\n",
       "      <td>-19.407303</td>\n",
       "      <td>-2.040268</td>\n",
       "      <td>...</td>\n",
       "      <td>0.037505</td>\n",
       "      <td>0.240895</td>\n",
       "      <td>-0.000184</td>\n",
       "      <td>4.027598</td>\n",
       "      <td>-0.032980</td>\n",
       "      <td>0.180784</td>\n",
       "      <td>0.000439</td>\n",
       "      <td>-83.073329</td>\n",
       "      <td>-0.038978</td>\n",
       "      <td>0.259474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1b2</th>\n",
       "      <td>114792076.0</td>\n",
       "      <td>51927.567127</td>\n",
       "      <td>2.498990</td>\n",
       "      <td>1.0</td>\n",
       "      <td>51935.942175</td>\n",
       "      <td>51935.942175</td>\n",
       "      <td>2.497538</td>\n",
       "      <td>0.132370</td>\n",
       "      <td>-25.436809</td>\n",
       "      <td>-2.761347</td>\n",
       "      <td>...</td>\n",
       "      <td>0.043319</td>\n",
       "      <td>0.245398</td>\n",
       "      <td>-0.000424</td>\n",
       "      <td>4.045005</td>\n",
       "      <td>-0.032608</td>\n",
       "      <td>0.184163</td>\n",
       "      <td>0.000575</td>\n",
       "      <td>-83.108080</td>\n",
       "      <td>-0.051755</td>\n",
       "      <td>0.264324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1c1</th>\n",
       "      <td>220729523.0</td>\n",
       "      <td>51825.443610</td>\n",
       "      <td>2.539644</td>\n",
       "      <td>1.0</td>\n",
       "      <td>51829.871078</td>\n",
       "      <td>51829.871078</td>\n",
       "      <td>2.537636</td>\n",
       "      <td>0.150480</td>\n",
       "      <td>13.910536</td>\n",
       "      <td>2.522709</td>\n",
       "      <td>...</td>\n",
       "      <td>0.043352</td>\n",
       "      <td>0.249338</td>\n",
       "      <td>-0.000289</td>\n",
       "      <td>4.058795</td>\n",
       "      <td>-0.034339</td>\n",
       "      <td>0.187120</td>\n",
       "      <td>0.000711</td>\n",
       "      <td>-82.878713</td>\n",
       "      <td>-0.070877</td>\n",
       "      <td>0.268568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1c2</th>\n",
       "      <td>280475611.0</td>\n",
       "      <td>51868.435913</td>\n",
       "      <td>2.712771</td>\n",
       "      <td>1.0</td>\n",
       "      <td>51869.872431</td>\n",
       "      <td>51869.872431</td>\n",
       "      <td>2.710388</td>\n",
       "      <td>0.157957</td>\n",
       "      <td>32.279093</td>\n",
       "      <td>5.704643</td>\n",
       "      <td>...</td>\n",
       "      <td>0.066771</td>\n",
       "      <td>0.266312</td>\n",
       "      <td>0.000242</td>\n",
       "      <td>3.070846</td>\n",
       "      <td>-0.034314</td>\n",
       "      <td>0.199858</td>\n",
       "      <td>0.000928</td>\n",
       "      <td>-82.990848</td>\n",
       "      <td>-0.085048</td>\n",
       "      <td>0.286850</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           ctags      km_total  BB_total   k1            m1           km1  \\\n",
       "1a1  485123992.0  51874.698930  2.631486  1.0  51881.842153  51881.842153   \n",
       "1b1  562216478.0  51944.382182  2.453179  1.0  51952.245993  51952.245993   \n",
       "1b2  114792076.0  51927.567127  2.498990  1.0  51935.942175  51935.942175   \n",
       "1c1  220729523.0  51825.443610  2.539644  1.0  51829.871078  51829.871078   \n",
       "1c2  280475611.0  51868.435913  2.712771  1.0  51869.872431  51869.872431   \n",
       "\n",
       "          BB1        k2         m2       km2  ...       km7       BB7  \\\n",
       "1a1  2.629353  0.150495  -4.464607 -0.218858  ...  0.043441  0.258350   \n",
       "1b1  2.451712  0.132500 -19.407303 -2.040268  ...  0.037505  0.240895   \n",
       "1b2  2.497538  0.132370 -25.436809 -2.761347  ...  0.043319  0.245398   \n",
       "1c1  2.537636  0.150480  13.910536  2.522709  ...  0.043352  0.249338   \n",
       "1c2  2.710388  0.157957  32.279093  5.704643  ...  0.066771  0.266312   \n",
       "\n",
       "           k8        m8       km8       BB8        k9         m9       km9  \\\n",
       "1a1  0.000073  3.676687 -0.031824  0.193882 -0.000274 -83.728230  0.018608   \n",
       "1b1 -0.000184  4.027598 -0.032980  0.180784  0.000439 -83.073329 -0.038978   \n",
       "1b2 -0.000424  4.045005 -0.032608  0.184163  0.000575 -83.108080 -0.051755   \n",
       "1c1 -0.000289  4.058795 -0.034339  0.187120  0.000711 -82.878713 -0.070877   \n",
       "1c2  0.000242  3.070846 -0.034314  0.199858  0.000928 -82.990848 -0.085048   \n",
       "\n",
       "          BB9  \n",
       "1a1  0.278274  \n",
       "1b1  0.259474  \n",
       "1b2  0.264324  \n",
       "1c1  0.268568  \n",
       "1c2  0.286850  \n",
       "\n",
       "[5 rows x 39 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_1_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stk = ['st'+str(st)+',k3' for st in range(72)]\n",
    "\n",
    "print np.mean(azi_run_k_df[stk].multiply(weight).sum(axis=1)/360)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_km[2]/np.mean(azi_run_k_df[stk].multiply(weight).sum(axis=1)/360)*16  # *0.0222*16/np.sqrt(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
