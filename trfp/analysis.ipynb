{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis\n",
    "Contains helper functions and main analysis functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Contains functions for analyzing trolley and fixed probe runs.\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.interpolate import interp1d\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import gm2\n",
    "import trfp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove trolley footprint\n",
    "Function that removes the trolley footprint from fixed probe measurements.\n",
    "Uses ring-wide drift as relacement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_trolley_effect(trolley_moment_df):\n",
    "    '''DOC STRING'''\n",
    "    veto_extent = 25\n",
    "    barcode = trfp.STATION_BARCODE_PHI\n",
    "    \n",
    "    trolley_effect_removed_df = trolley_moment_df.copy()\n",
    "    \n",
    "    for st in range(72):\n",
    "        print '\\rRemoving trolley image from station ' + str(st) + '.',\n",
    "        for m in range(1,7):\n",
    "            st_m = 'st' + str(st) + \",m\" + str(m)\n",
    "            \n",
    "            # Unwrap the fixed probe data versus trolley position\n",
    "            raw_data = trolley_moment_df[['tr_phi', st_m]].copy()\n",
    "            raw_low = raw_data.copy()\n",
    "            raw_high = raw_data.copy()\n",
    "            raw_low['tr_phi'] = raw_low['tr_phi'] - 360\n",
    "            raw_high['tr_phi'] = raw_high['tr_phi'] + 360\n",
    "            unwrap_nomask_df = pd.concat([raw_low, raw_data, raw_high])\n",
    "            \n",
    "            unwrap_mask_df = unwrap_nomask_df.copy()\n",
    "#             mask = ((unwrap_nomask_df['tr_phi']>barcode[st]-2) & (unwrap_nomask_df['tr_phi']<barcode[st]+5) |\n",
    "#                     (unwrap_nomask_df['tr_phi']>barcode[st]-2-360) & (unwrap_nomask_df['tr_phi']<barcode[st]+5-360) |\n",
    "#                     (unwrap_nomask_df['tr_phi']>barcode[st]-2+360) & (unwrap_nomask_df['tr_phi']<barcode[st]+5+360))\n",
    "            veto_adjust = (veto_extent-7)/2\n",
    "            mask = (  (unwrap_nomask_df['tr_phi']>barcode[st]-2-veto_adjust)\n",
    "                       & (unwrap_nomask_df['tr_phi']<barcode[st]+5+veto_adjust)\n",
    "                    | (unwrap_nomask_df['tr_phi']>barcode[st]-2-veto_adjust-360)\n",
    "                       & (unwrap_nomask_df['tr_phi']<barcode[st]+5+veto_adjust-360)\n",
    "                    | (unwrap_nomask_df['tr_phi']>barcode[st]-2-veto_adjust+360)\n",
    "                       & (unwrap_nomask_df['tr_phi']<barcode[st]+5+veto_adjust+360))\n",
    "            \n",
    "            unwrap_mask_df[st_m] = unwrap_nomask_df[st_m].mask(mask)\n",
    "            unwrap_mask_df['tr_phi'] = unwrap_nomask_df['tr_phi']\n",
    "            \n",
    "            unwrap_filled_df = unwrap_mask_df.copy()\n",
    "            temp = unwrap_filled_df.rolling(int(500),win_type='triang',min_periods=1,center=True).mean()\n",
    "            temp = temp.rolling(int(500),win_type='triang',min_periods=1,center=True).mean()\n",
    "            unwrap_filled_df[st_m] = unwrap_filled_df[st_m].mask(mask, temp[st_m])\n",
    "            \n",
    "            length = raw_data.shape[0]\n",
    "            filled_df = unwrap_filled_df.iloc[length:2*length,:]\n",
    "            \n",
    "            trolley_effect_removed_df[st_m] = filled_df[st_m]\n",
    "    \n",
    "    print '\\rFinished removing trolley images from ' + str(length) + ' events.'\n",
    "    return trolley_effect_removed_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Average fields station-wise during trolley runs\n",
    "Calculates average moments during trolley from for synchronization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trolley_run_station_average(corrected_df):\n",
    "    station_phi = trfp.STATION_BARCODE_PHI\n",
    "    station_edges = trfp.STATION_BARCODE_EDGES\n",
    "\n",
    "    # tr_phi is not monotonic, so sort by tr_phi\n",
    "\n",
    "    corrected_df = corrected_df.sort_values(by=['tr_phi'])\n",
    "\n",
    "    measured_phi = corrected_df['tr_phi'].values\n",
    "    measured_extent = (np.roll(measured_phi,-1)-np.roll(measured_phi,1))/2\n",
    "    measured_extent[0] = measured_extent[0]+180\n",
    "    measured_extent[-1] = measured_extent[-1]+180\n",
    "    # print np.max(measured_extent)\n",
    "\n",
    "    corrected_df['tr_extent'] = pd.Series(measured_extent, index=corrected_df.index)\n",
    "    corrected_df = corrected_df.sort_index()\n",
    "\n",
    "    # for a given station:\n",
    "    # create a mask for when trolley is in [low edge, high edge)\n",
    "    tr_baseline = np.empty([72,17])\n",
    "    fp_baseline = np.empty([72,6])\n",
    "    summed_azimuth = np.empty(72)\n",
    "    summed_pts = np.empty(72)\n",
    "    baseline_time = np.empty(72)\n",
    "    tr_baseline[:] = np.nan\n",
    "    fp_baseline[:] = np.nan\n",
    "    summed_azimuth[:] = np.nan\n",
    "    summed_pts[:] = np.nan\n",
    "    baseline_time[:] = np.nan\n",
    "\n",
    "    for st in range(72): \n",
    "        if station_edges[st+1] > station_edges[st]:\n",
    "            mask = (corrected_df['tr_phi'] >= station_edges[st]) & (corrected_df['tr_phi'] < station_edges[st+1])\n",
    "        else:  # case where we go over the 360 deg line\n",
    "            mask = (corrected_df['tr_phi'] >= station_edges[st]) | (corrected_df['tr_phi'] < station_edges[st+1])\n",
    "\n",
    "        out_df = corrected_df[mask]\n",
    "        summed_pts[st] = out_df.shape[0]\n",
    "        summed_azimuth[st] = sum(out_df['tr_extent'].values)        \n",
    "        baseline_time[st] = sum(out_df.index.values)/summed_pts[st]\n",
    "\n",
    "        for m in range(17):\n",
    "            st_id = 'tr,m'+str(m+1)\n",
    "            if sum(out_df['tr_extent'].values) != 0:\n",
    "                tr_baseline[st, m] = sum(out_df['tr_extent'].values*out_df[st_id].values)/sum(out_df['tr_extent'].values)\n",
    "            else:\n",
    "                tr_baseline[st, m] = np.nan\n",
    "        for m in range(6):\n",
    "            st_id = 'st'+str(st)+',m'+str(m+1)\n",
    "            if sum(out_df['tr_extent'].values) != 0:\n",
    "                fp_baseline[st, m] = np.mean(out_df[st_id])\n",
    "            else:\n",
    "                fp_baseline[st, m] = np.nan\n",
    "    \n",
    "    return tr_baseline, fp_baseline, baseline_time, summed_azimuth, summed_pts"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
