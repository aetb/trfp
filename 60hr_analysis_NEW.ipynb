{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "import gm2\n",
    "import trfp\n",
    "import plotting_functions as plt2\n",
    "import analysis_helper as helper\n",
    "import helper_function_candidates as helper_old"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Load data, calculate vtms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "fp_interp_df = helper.root_to_pandas(range(3959,3995), prefix='v9_20_00/FieldPlainRootOutput_', tr_run=False)\n",
    "tr_interp_df_1 = helper.root_to_pandas([3956], prefix='v9_20_00/FieldPlainRootOutput_', tr_run=True)\n",
    "tr_interp_df_2 = helper.root_to_pandas([3997], prefix='v9_20_00/FieldPlainRootOutput_', tr_run=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "fp_moment_df = helper.calc_moment_df(fp_interp_df)\n",
    "tr_moment_df_1 = helper.calc_moment_df(tr_interp_df_1)\n",
    "tr_moment_df_2 = helper.calc_moment_df(tr_interp_df_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "tr_corr_df_1 = helper_old.trolley_footprint_replacement(tr_moment_df_1)\n",
    "tr_corr_df_2 = helper_old.trolley_footprint_replacement(tr_moment_df_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "tr_baseline_1, fp_baseline_1, baseline_time_1, summed_azimuth_1, summed_pts_1 = helper_old.trolley_run_station_average(tr_corr_df_1)\n",
    "tr_baseline_2, fp_baseline_2, baseline_time_2, summed_azimuth_2, summed_pts_2 = helper_old.trolley_run_station_average(tr_corr_df_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "vtm_df = helper.vtm_calc(fp_moment_df,\n",
    "                         baseline_time_1, baseline_time_2,\n",
    "                         tr_baseline_1, tr_baseline_2,\n",
    "                         fp_baseline_1, fp_baseline_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Time and azimuthal averaging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Read in ctags and $\\omega_a$ subrun status for time averaging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "### Read in ctag info\n",
    "\n",
    "subrun_df = pd.read_hdf('60hr_subrun.h5', key='ctag')\n",
    "usable_subruns_df = subrun_df[subrun_df['ok']==True].copy()\n",
    "\n",
    "### Bin by subrun\n",
    "\n",
    "intervals = []\n",
    "interval_centers = []\n",
    "interval_range = []\n",
    "for ii in range(usable_subruns_df['end_gps'].values.size):\n",
    "    intervals.append(pd.Interval(usable_subruns_df['start_gps'].values[ii],\n",
    "                                 usable_subruns_df['end_gps'].values[ii],\n",
    "                                 closed='both'\n",
    "                                )\n",
    "                    )\n",
    "    interval_centers.append((usable_subruns_df['start_gps'].values[ii] + usable_subruns_df['end_gps'].values[ii])/2)\n",
    "    interval_range.append(usable_subruns_df['end_gps'].values[ii] - usable_subruns_df['start_gps'].values[ii])\n",
    "    \n",
    "intervals = pd.IntervalIndex(intervals)\n",
    "interval_centers = np.array(interval_centers)\n",
    "interval_range = np.array(interval_range)\n",
    "\n",
    "vtm_bin_df = vtm_df.groupby(pd.cut(vtm_df.index, intervals)).mean()\n",
    "vtm_bin_df['bin_range'] = interval_range\n",
    "vtm_bin_df['start_gps'] = usable_subruns_df['start_gps'].values\n",
    "\n",
    "vtm_bin_df = vtm_bin_df.merge(usable_subruns_df[['start_gps', 'ctags']])\n",
    "vtm_bin_df.index = interval_centers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Time average, weighted by ctags in \"ok\" subruns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "stms = ['st'+str(st)+',m'+str(m+1) for st in range(72) for m in range(6)]\n",
    "time_avg_series = vtm_bin_df[stms].multiply(vtm_bin_df['ctags'], axis='index').sum()/vtm_bin_df['ctags'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Naive azimuthal average, weighted by fixed probe station extent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "azi_avg_series = pd.Series(index = ['m' + str(m) for m in np.arange(6)+1])\n",
    "\n",
    "for m in range(5):\n",
    "    weight = summed_azimuth_1[:, m] + summed_azimuth_2[:, m]\n",
    "    \n",
    "    total_weight = np.nansum(weight)\n",
    "    stm_list = ['st'+str(st)+',m'+str(m+1) for st in np.arange(72)]\n",
    "    azi_avg_series['m'+str(m+1)] = time_avg_series[stm_list].multiply(weight).sum()/total_weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Legacy code/studies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Alan studies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import allantools\n",
    "\n",
    "fig, ax = plt.subplots(1,1)\n",
    "for st in range(7):\n",
    "    stm = 'st'+str(st)+',m1'\n",
    "    tau, adev, _, _ = allantools.mdev(fp_moment_df[stm].values/61.79, data_type='freq', taus='decade')\n",
    "    plt.loglog(tau, adev, '.', label=stm)\n",
    "plt.legend()\n",
    "fig.set_size_inches(12,8)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Sync Offsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sync_offsets, delta_t = helper.sync_offset_calc(tr_corr_df_1, tr_corr_df_2)\n",
    "\n",
    "def gaussian(x, A, x0, sigma): return A*np.exp(-(x-x0)**2/2./sigma**2)\n",
    "\n",
    "fig, axs = plt.subplots(2,3)\n",
    "for i in range(2):\n",
    "    for j in range(3):\n",
    "        st = 3*i+j\n",
    "        if st == 5: continue\n",
    "            \n",
    "        plt.sca(axs[i,j])\n",
    "        hist, bins, _ = plt.hist(sync_offsets[:,st], bins=50)\n",
    "        low, high = axs[i,j].get_xlim()\n",
    "                \n",
    "        bins = bins[0:-1] + 0.5*(bins[1]-bins[0])\n",
    "        coeffs, _ = curve_fit(gaussian, bins, hist, p0=[1., 0., 10.])\n",
    "        fit = gaussian(np.arange(low, high, 0.1), coeffs[0], coeffs[1], coeffs[2])\n",
    "        plt.plot(np.arange(low,high,0.1), fit, label=r'$\\omega_0$ = '+str(np.round(coeffs[1],1))+'\\n$\\sigma$ = '+str(np.round(coeffs[2],1)))\n",
    "        plt.legend(loc=1)\n",
    "        plt2.plt_set_labels(axs[i,j], 'sync offset (Hz)', '', 'm '+str(st+1))\n",
    "        \n",
    "        if st == 0: plt.xlim(-100,100)\n",
    "        else: plt.xlim(-50,50)\n",
    "\n",
    "\n",
    "fig.set_size_inches(12,8)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Extended trolley averages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# calculate extended trolley averages\n",
    "\n",
    "print np.sum(tr_baseline_1*summed_azimuth_1, axis=0)/360\n",
    "\n",
    "print '\\n'\n",
    "\n",
    "print np.sum(tr_baseline_2*summed_azimuth_2, axis=0)/360"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Legacy time/azimuthal averaging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "### Bin into the agreed upon bins\n",
    "\n",
    "bins = np.arange(1524384055, 1524641055, 1000)-500  # bin edges\n",
    "bin_centers = np.arange(1524384055, 1524640055, 1000)\n",
    "\n",
    "vtm_bin_df = vtm_df.groupby(pd.cut(vtm_df.index, bins)).mean()\n",
    "vtm_bin_df.index = bin_centers\n",
    "\n",
    "test_df = vtm_bin_df.copy()\n",
    "\n",
    "azi_avg_df = pd.DataFrame(np.zeros((test_df.shape[0],6)),\n",
    "                         index = test_df.index,\n",
    "                         columns = ['m' + str(m) for m in np.arange(6)+1])\n",
    "\n",
    "for m in range(5):\n",
    "    weight = summed_azimuth_1[:, m] + summed_azimuth_2[:, m]\n",
    "    \n",
    "    # de-weight station 5 (split into 4 and 6 by distance to each)\n",
    "    weight[4] += weight[5] * (trfp.STATION_BARCODE_PHI[6]-trfp.STATION_BARCODE_PHI[5])/(trfp.STATION_BARCODE_PHI[6]-trfp.STATION_BARCODE_PHI[4])\n",
    "    weight[6] += weight[5] * (trfp.STATION_BARCODE_PHI[5]-trfp.STATION_BARCODE_PHI[4])/(trfp.STATION_BARCODE_PHI[6]-trfp.STATION_BARCODE_PHI[4])\n",
    "    weight[5] = 0\n",
    "    \n",
    "    total_weight = np.nansum(weight)\n",
    "    stm_list = ['st'+str(st)+',m'+str(m+1) for st in np.arange(72)]\n",
    "    azi_avg_df['m'+str(m+1)] = test_df[stm_list].multiply(weight).sum(axis=1)/total_weight\n",
    "    \n",
    "print_df = azi_avg_df[['m1','m2','m3','m5']].copy()/61.79\n",
    "print_df['m1_err'] = 0.116\n",
    "print_df['m2_err'] = 0.06\n",
    "print_df['m3_err'] = 0.06\n",
    "print_df['m5_err'] = 0.1\n",
    "\n",
    "print_df = print_df.sort_index(axis='columns')\n",
    "# print_df.head()\n",
    "# print_df.to_csv('purcell_60hr_7-31.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# print all stations\n",
    "\n",
    "fig, axs = plt.subplots(24,3)\n",
    "\n",
    "for i in range(24):\n",
    "    for j in range(3):\n",
    "        plt.sca(axs[i,j])\n",
    "        st = i*3 + j\n",
    "        plt.plot(vtm_bin_df.index.values, vtm_bin_df['st'+str(st)+',m5']/61.79, '.', markersize=1, color='navy')\n",
    "        plt2.plt_set_labels(axs[i,j], '', 'NS (ppm)', 'st '+str(st))\n",
    "        plt2.plt_unix_time_to_CST(axs[i,j])\n",
    "\n",
    "fig.set_size_inches(16, 80)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Compare with Rachel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "rachel_m1 = np.loadtxt('rachel_m1_st135.txt')\n",
    "\n",
    "fig, axs = plt.subplots(24,3)\n",
    "\n",
    "for i in range(24):\n",
    "    for j in range(3):\n",
    "        plt.sca(axs[i,j])\n",
    "        st = i*3 + j\n",
    "#         if st == 71: continue\n",
    "        plt.plot(vtm_bin_df.index.values, vtm_bin_df['st'+str(st)+',m1']/61.79 - rachel_m1[:,st], '.', markersize=1, color='navy')\n",
    "        plt2.plt_set_labels(axs[i,j], '', 'Dipole (ppm)', 'st '+str(st))\n",
    "        plt2.plt_unix_time_to_CST(axs[i,j])\n",
    "\n",
    "fig.set_size_inches(16, 80)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
