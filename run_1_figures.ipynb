{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import pickle\n",
    "import dill\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from scipy.stats import binned_statistic\n",
    "from scipy.optimize import curve_fit\n",
    "from scipy.interpolate import interp1d\n",
    "\n",
    "import gm2\n",
    "import trfp\n",
    "import plotting_functions as plt2\n",
    "# import analysis_helper as helper\n",
    "# import helper_function_candidates as helper_old\n",
    "# import df_analysis_funcs as df_func\n",
    "import helper_functions as helper\n",
    "\n",
    "import muon_dist_config_run1 as dist_config\n",
    "import field_map_config_run1 as map_config\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "# blinds = np.loadtxt('blinds.txt')\n",
    "pair_dict = map_config.pair_dict\n",
    "\n",
    "def bins(df, num_bins):\n",
    "    xy_df = df.groupby(pd.cut(df.index.values, num_bins)).mean()\n",
    "    x = np.empty(xy_df.shape[0])\n",
    "    ii = 0\n",
    "    for interval in xy_df.index:\n",
    "        x[ii] = interval.mid\n",
    "        ii = ii + 1\n",
    "    y = xy_df.values\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_width = 3.375 * 2  # inches, two column\n",
    "\n",
    "plt.style.use('gm2.mplstyle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = '1a'\n",
    "\n",
    "filename = 'hdf5/2020-09-30_run_' + run + '.h5'\n",
    "\n",
    "interp_dfs, keys, subrun_df = helper.read_dfs(filename)\n",
    "run_pair_dict = pair_dict[run]\n",
    "\n",
    "moment_dfs = helper.interp_to_moment(interp_dfs, keys)\n",
    "# moment_dfs = blind_moments(moment_dfs, keys, blinds)\n",
    "corrected_dfs = helper.moment_to_corrected(moment_dfs, keys)\n",
    "\n",
    "baselines = helper.station_average(corrected_dfs, keys)\n",
    "\n",
    "## for endgame only\n",
    "# for item in baselines:\n",
    "#     baselines[item]['tr_df_9'] = baselines[item]['tr_df_8']\n",
    "# baselines['time']['tr_df_9'] = baselines['time']['tr_df_7']\n",
    "\n",
    "vtm_dfs = helper.calculate_vtms(corrected_dfs, keys, baselines, run_pair_dict)\n",
    "\n",
    "bloch_style_dfs = helper.bloch_style_moments(corrected_dfs, keys)\n",
    "baselines_bloch = helper.station_average(bloch_style_dfs, keys)\n",
    "\n",
    "## for endgame only\n",
    "# for item in baselines_bloch:\n",
    "#     baselines_bloch[item]['tr_df_9'] = baselines_bloch[item]['tr_df_8']\n",
    "# baselines_bloch['time']['tr_df_9'] = baselines_bloch['time']['tr_df_7']\n",
    "\n",
    "vtm_dfs_bloch = helper.calculate_vtms(bloch_style_dfs, keys, baselines_bloch, run_pair_dict)\n",
    "\n",
    "# clear_output()\n",
    "\n",
    "# for key in vtm_dfs.keys():\n",
    "#     a = vtm_dfs[key].index.values\n",
    "#     bins = np.array([a,a]).T.flatten()[:len(a)]\n",
    "\n",
    "#     vtm_2_sec_df = vtm_dfs_bloch[key].groupby(bins).mean()\n",
    "#     vtm_2_sec_df = vtm_2_sec_df.set_index((a[::2]+0.5))\n",
    "\n",
    "#     weight = trfp.STATION_BARCODE_EDGES[1:] - trfp.STATION_BARCODE_EDGES[:-1]\n",
    "#     weight[2] = weight[2] + 360\n",
    "\n",
    "#     vtm_2_sec_azi_avg_df = pd.DataFrame(index=vtm_2_sec_df.index)\n",
    "\n",
    "#     for m in range(9):\n",
    "#         stm_list = ['st'+str(st)+',m'+str(m+1) for st in np.arange(72)]\n",
    "#         vtm_2_sec_azi_avg_df['m'+str(m+1)] = vtm_2_sec_df[stm_list].multiply(weight).sum(axis=1)/360\n",
    "\n",
    "#     # need to save 4 data frames\n",
    "\n",
    "#     save_key = 'run_' + run + key[6]\n",
    "#     save_dir = 'hdf5/'\n",
    "#     save_prefix = '2020-09-30_'\n",
    "\n",
    "#     print 'Saving ' + save_key\n",
    "\n",
    "#     # save purcell style\n",
    "\n",
    "#     save_path = save_dir + save_prefix + 'purcell_maps.h5'\n",
    "#     vtm_dfs[key].to_hdf(save_path, key=save_key)\n",
    "\n",
    "#     # save hybrid\n",
    "\n",
    "#     save_path = save_dir + save_prefix + 'hybrid_maps.h5'\n",
    "#     vtm_dfs_bloch[key].to_hdf(save_path, key=save_key)\n",
    "\n",
    "#     # save 2 sec hybrid\n",
    "\n",
    "#     save_path = save_dir + save_prefix + 'hybrid_maps_2sec.h5'\n",
    "#     vtm_2_sec_df.to_hdf(save_path, key=save_key)\n",
    "\n",
    "#     # save 2 sec azi avg hybrid\n",
    "\n",
    "#     save_path = save_dir + save_prefix + 'hybrid_maps_2sec_aziavg.h5'\n",
    "#     vtm_2_sec_azi_avg_df.to_hdf(save_path, key=save_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bins(df, num_bins):\n",
    "    xy_df = df.groupby(pd.cut(df.index.values, num_bins)).mean()\n",
    "    x = np.empty(xy_df.size)\n",
    "    ii = 0\n",
    "    for interval in xy_df.index:\n",
    "        x[ii] = interval.mid\n",
    "        ii = ii + 1\n",
    "    y = xy_df.values\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## fig:footprint_replacement\n",
    "\n",
    "fig_name = 'fig_footprint_replacement'\n",
    "\n",
    "st = 10\n",
    "m = 1\n",
    "df = 'tr_df_1'\n",
    "\n",
    "veto_extent=25\n",
    "no_mask_df = moment_dfs[df].copy()\n",
    "t0 = no_mask_df.index.values[0]\n",
    "no_mask_df.index -= t0\n",
    "index = no_mask_df.index.values\n",
    "\n",
    "print '\\rRemoving trolley image from station '+str(st)+'.',\n",
    "\n",
    "# veto when trolley is close to station\n",
    "\n",
    "veto_low = (trfp.STATION_BARCODE_PHI[st]-1.5-veto_extent/2)%360\n",
    "veto_high = (trfp.STATION_BARCODE_PHI[st]-1.5+veto_extent/2)%360\n",
    "if veto_low < veto_high:\n",
    "    veto_mask = (no_mask_df['tr_phi']>veto_low) & (no_mask_df['tr_phi']<veto_high)\n",
    "else:  # this happens when wrapping around 360 deg\n",
    "    veto_mask = (no_mask_df['tr_phi']>veto_low) | (no_mask_df['tr_phi']<veto_high)\n",
    "\n",
    "# no longer dealing with m6 in the fixed probes\n",
    "\n",
    "\n",
    "stm = 'st'+str(st)+',m'+str(m)\n",
    "\n",
    "# calculate local drift\n",
    "\n",
    "times = no_mask_df.index.values[~veto_mask]\n",
    "freqs = no_mask_df[stm][~veto_mask]\n",
    "\n",
    "local_drift_fit = np.polyfit(times, freqs, 5)\n",
    "local_drift = np.polyval(local_drift_fit, no_mask_df.index.values)\n",
    "\n",
    "# need to average other side of ring\n",
    "all_good_stations = np.arange(6,72)  # not using the inflector stations\n",
    "no_ground_loop_stations = np.array(range(6,16)+range(64,72))  # vaid for 25 deg veto\n",
    "\n",
    "# next need to average all good stations that are not within 3 of current station\n",
    "if st not in range(16, 23):  # note that these ranged were chosen for 25 deg veto\n",
    "    averaging_stations = np.delete(all_good_stations,\n",
    "                                   np.argwhere((np.abs((all_good_stations - st)%72)<=3)\n",
    "                                              | (np.abs((all_good_stations - st)%72)>=69))\n",
    "                                  )\n",
    "else:\n",
    "    averaging_stations = np.delete(no_ground_loop_stations,\n",
    "                                   np.argwhere((np.abs((no_ground_loop_stations - st)%72)<=3)\n",
    "                                              | (np.abs((no_ground_loop_stations - st)%72)>=69))\n",
    "                                  )\n",
    "avg_stms = ['st'+str(avg_st)+',m'+str(m+1) for avg_st in averaging_stations]\n",
    "replacement = no_mask_df[avg_stms].mean(axis=1)\n",
    "\n",
    "# calculate global drift\n",
    "global_drift_fit = np.polyfit(index[veto_mask], replacement[veto_mask], 1)\n",
    "global_drift = np.polyval(global_drift_fit, index[veto_mask])\n",
    "\n",
    "# subtract global drift from replacement\n",
    "replacement = replacement[veto_mask] - global_drift\n",
    "\n",
    "# add local drift\n",
    "replacement = replacement + local_drift[veto_mask]\n",
    "\n",
    "no_mask_df[stm][veto_mask] = replacement\n",
    "\n",
    "raw_data = moment_dfs[df][stm].copy()\n",
    "raw_data.index -= raw_data.index.values[0]\n",
    "\n",
    "x0, y0 = bins(raw_data[~veto_mask], raw_data[~veto_mask].size/2)\n",
    "x3, y3 = bins(raw_data[veto_mask], raw_data[veto_mask].size/2)\n",
    "\n",
    "unvetoed = no_mask_df[stm][~veto_mask].copy()\n",
    "x1, y1 = bins(unvetoed, unvetoed.size/2)\n",
    "replace = no_mask_df[stm][veto_mask].copy()\n",
    "x2, y2 = bins(replace, replace.size/2)\n",
    "\n",
    "fig2, axs2 = plt.subplots(2, 1, sharex=True)\n",
    "\n",
    "axs2[0].plot(x0, y0+61.74e6, '.', ms=6)\n",
    "axs2[0].plot(x3, y3+61.74e6, '.', ms=6, label='vetoed')\n",
    "axs2[0].legend()\n",
    "\n",
    "axs2[1].plot(x1, y1+61.74e6, '.', ms=6)\n",
    "axs2[1].plot(x2, y2+61.74e6, '.', ms=6, label='replacement')\n",
    "axs2[1].legend()\n",
    "\n",
    "axs2[1].set_xlabel('Time (sec)')\n",
    "\n",
    "fig2.text(0, 0.5, 'NMR freq (Hz)', va='center', rotation='vertical')\n",
    "\n",
    "fig2.set_size_inches(fig_width, fig_width)\n",
    "fig2.tight_layout()\n",
    "\n",
    "fig2.savefig('figures/run_1/'+fig_name+'.png', dpi=300)\n",
    "pickle.dump(axs2, open('figures/run_1/'+fig_name+'.pickle', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## fig:backward_interp\n",
    "fig_name = 'fig_backward_interp'\n",
    "\n",
    "fig1, axs1 = plt.subplots(1,1)\n",
    "\n",
    "st = 42\n",
    "m = 1\n",
    "\n",
    "df = 'fp_df_1'\n",
    "stm = 'st'+str(st)+',m'+str(m)\n",
    "stm5 = 'st'+str(st)+',m5'\n",
    "\n",
    "x0 = 0\n",
    "x1 = (baselines['time']['tr_df_2'][st] - baselines['time']['tr_df_1'][st])/3600.\n",
    "\n",
    "\n",
    "pre_corr = (moment_dfs[df][stm] - baselines['fp']['tr_df_1'][st,m-1] + baselines['tr']['tr_df_1'][st,m-1]\n",
    "            + 2.631605 * (moment_dfs[df][stm5] - baselines['fp']['tr_df_1'][st,4])\n",
    "           )\n",
    "x, pre_corr = bins(pre_corr, pre_corr.size/600)\n",
    "post_corr = vtm_dfs[df][stm]\n",
    "_, post_corr = bins(post_corr, post_corr.size/600)\n",
    "\n",
    "x = x - baselines['time']['tr_df_1'][st]\n",
    "x = x/3600.\n",
    "\n",
    "\n",
    "\n",
    "axs1.plot(x, post_corr+61.74e6, '.', markersize=6, label='corrected')\n",
    "axs1.plot(x, pre_corr+61.74e6, '.', markersize=6, label='uncorrected')\n",
    "\n",
    "axs1.plot(x0, baselines['tr']['tr_df_1'][st,m-1]+61.74e6, 'x', color='C2', mew=5, markersize=10, label='trolley value 1')\n",
    "axs1.plot(x1, baselines['tr']['tr_df_2'][st,m-1]+61.74e6, 'x', color='C3', mew=5, markersize=10, label='trolley value 2')\n",
    "\n",
    "axs1.legend()\n",
    "\n",
    "axs1.set_xlabel('Time (h)')\n",
    "axs1.set_ylabel('NMR freq (Hz)')\n",
    "\n",
    "fig1.set_size_inches(fig_width,0.75*fig_width)\n",
    "fig1.tight_layout()\n",
    "\n",
    "fig1.savefig('figures/run_1/'+fig_name+'.png', dpi=300)\n",
    "pickle.dump(axs1, open('figures/run_1/'+fig_name+'.pickle', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## fig:team_diffs\n",
    "\n",
    "fig_name = 'fig_team_diffs'\n",
    "\n",
    "bloch_df = pd.read_csv('/data2/scharity/Run1/FinalUnblindingOct2020/60Hr_3956-3997_for_alec.csv', index_col=0)\n",
    "purcell_df = pd.read_hdf('/data2/aetb/2020-09-30_purcell_maps.h5', key='run_1a1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight = (trfp.STATION_BARCODE_EDGES[1:] - trfp.STATION_BARCODE_EDGES[:-1])\n",
    "weight[2] = (weight[2] + 360)\n",
    "weight = weight/360\n",
    "\n",
    "for m in range(9):\n",
    "    stm = ['st'+str(st)+',m'+str(m+1) for st in range(72)]\n",
    "    purcell_df['m'+str(m+1)] = purcell_df[stm].multiply(weight).sum(axis=1)\n",
    "\n",
    "fig3, axs3 = plt.subplots(2, 1, sharex=True)\n",
    "\n",
    "xp, yp = bins(purcell_df['m1'], num_bins=purcell_df['m1'].size/1000)\n",
    "xb, yb = bins(bloch_df['dipole'], num_bins=bloch_df['dipole'].size/1)\n",
    "yb *= 61.79\n",
    "\n",
    "xd = xp\n",
    "yd = np.interp(xp, xb, yb) - yp\n",
    "\n",
    "xb = (xb - xp[0])/3600\n",
    "xd = (xd - xp[0])/3600\n",
    "xp = (xp - xp[0])/3600\n",
    "\n",
    "axs3[0].plot(xp, yp + 61.74e6, '.', label='Team 2')\n",
    "axs3[0].plot(xb, yb + 61.74e6, '.', label='Team 1')\n",
    "axs3[0].legend()\n",
    "axs3[1].plot(xd, yd, '.')\n",
    "\n",
    "axs3[0].set_ylabel('NMR freq (Hz)')\n",
    "axs3[1].set_ylabel('Team diff (Hz)')\n",
    "axs3[1].set_xlabel('Time (h)')\n",
    "\n",
    "fig3.set_size_inches(fig_width, fig_width)\n",
    "fig3.tight_layout()\n",
    "\n",
    "fig3.savefig('figures/run_1/'+fig_name+'.png', dpi=300)\n",
    "pickle.dump(axs3, open('figures/run_1/'+fig_name+'.pickle', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## fig:team_diffs_avg\n",
    "\n",
    "fig_name = 'fig_team_diffs_avg'\n",
    "\n",
    "bloch_purcell_dict = {'run_1a1':'/data2/scharity/Run1/FinalUnblindingOct2020/60Hr_3956-3997_for_alec.csv',\n",
    "                      'run_1b1':'/data2/scharity/Run1/FinalUnblindingOct2020/HighKick_4058-4098_for_alec.csv',\n",
    "                      'run_1b2':'/data2/scharity/Run1/FinalUnblindingOct2020/HighKick_4098-4138_for_alec.csv',\n",
    "                      'run_1c1':'/data2/scharity/Run1/FinalUnblindingOct2020/9day_4138-4181_for_alec.csv',\n",
    "                      'run_1c2':'/data2/scharity/Run1/FinalUnblindingOct2020/9day_4189-4226_for_alec.csv',\n",
    "                      'run_1c3':'/data2/scharity/Run1/FinalUnblindingOct2020/9day_4226-4265_for_alec.csv',\n",
    "                      'run_1d2':'/data2/scharity/Run1/FinalUnblindingOct2020/endgame_5054-5103_for_alec.csv',\n",
    "                      'run_1d3':'/data2/scharity/Run1/FinalUnblindingOct2020/endgame_5117-5157_for_alec.csv',\n",
    "                      'run_1d4':'/data2/scharity/Run1/FinalUnblindingOct2020/endgame_5169-5217_for_alec.csv',\n",
    "                      'run_1d5':'/data2/scharity/Run1/FinalUnblindingOct2020/endgame_5217-5259_for_alec.csv',\n",
    "                      'run_1d6':'/data2/scharity/Run1/FinalUnblindingOct2020/endgame_5259-5303_for_alec.csv'}\n",
    "\n",
    "bloch_avg = np.empty(11)\n",
    "purc_avg = np.empty(11)\n",
    "diff_avg = np.empty(11)\n",
    "\n",
    "weight = (trfp.STATION_BARCODE_EDGES[1:] - trfp.STATION_BARCODE_EDGES[:-1])\n",
    "weight[2] = (weight[2] + 360)\n",
    "weight = weight/360\n",
    "\n",
    "ii = 0\n",
    "for run in bloch_purcell_dict:\n",
    "    print run\n",
    "    bloch_df = pd.read_csv(bloch_purcell_dict[run], index_col=0)\n",
    "    purcell_df = pd.read_hdf('/data2/aetb/2020-09-30_purcell_maps.h5', key=run)\n",
    "    for m in range(9):\n",
    "        stm = ['st'+str(st)+',m'+str(m+1) for st in range(72)]\n",
    "        purcell_df['m'+str(m+1)] = purcell_df[stm].multiply(weight).sum(axis=1)\n",
    "    xp, yp = bins(purcell_df['m1'], num_bins=purcell_df['m1'].size/1000)\n",
    "    xb, yb = bins(bloch_df['dipole'], num_bins=bloch_df['dipole'].size/1)\n",
    "    yb *= 61.79\n",
    "\n",
    "    xd = xp\n",
    "    yd = np.interp(xp, xb, yb) - yp\n",
    "\n",
    "    xb = (xb - xp[0])/3600\n",
    "    xd = (xd - xp[0])/3600\n",
    "    xp = (xp - xp[0])/3600\n",
    "    \n",
    "    bloch_avg[ii] = np.polyfit(xb, yb, 0)\n",
    "    purc_avg[ii] = np.polyfit(xp, yp, 0)\n",
    "    diff_avg[ii] = np.polyfit(xd, yd, 0)\n",
    "    \n",
    "    ii += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_name = 'fig_team_diffs_avg'\n",
    "\n",
    "fig4, axs4 = plt.subplots(1,1)\n",
    "\n",
    "axs4.hist(diff_avg, bins=np.arange(-1.75, 2, 0.5))\n",
    "axs4.vlines(np.mean(diff_avg), 0, 3, color='C1', linewidths=3, label='mean')\n",
    "axs4.vlines(np.mean(diff_avg) - np.std(diff_avg)/np.sqrt(11), 0, 3, color='C1', linewidths=3, linestyles='dotted', label='mean error')\n",
    "axs4.vlines(np.mean(diff_avg) + np.std(diff_avg)/np.sqrt(11), 0, 3, color='C1', linewidths=3, linestyles='dotted')\n",
    "axs4.legend()\n",
    "\n",
    "axs4.set_xlabel('Avg team diff (Hz)')\n",
    "axs4.set_ylabel('Number of trolley pairs')\n",
    "axs4.set_yticks([0,1,2,3])\n",
    "\n",
    "fig4.set_size_inches(fig_width, 0.75*fig_width)\n",
    "fig4.tight_layout()\n",
    "\n",
    "fig4.savefig('figures/run_1/'+fig_name+'.png', dpi=300)\n",
    "pickle.dump(axs4, open('figures/run_1/'+fig_name+'.pickle', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## fig:run1_track\n",
    "\n",
    "fig_name = 'fig_run1_track'\n",
    "\n",
    "x = np.empty(0)\n",
    "y1 = np.empty(0)\n",
    "y2 = np.empty(0)\n",
    "for run in map_config.subruns:\n",
    "    print run\n",
    "    df = pd.read_hdf('/data2/aetb/2020-09-30_purcell_maps.h5', key='run_'+run)\n",
    "    for m in range(2):\n",
    "        stm = ['st'+str(st)+',m'+str(m+1) for st in range(72)]\n",
    "        df['m'+str(m+1)] = df[stm].multiply(weight).sum(axis=1)\n",
    "    _x, _y1 = bins(df['m1'], df['m1'].size/1200)\n",
    "    _x, _y2 = bins(df['m2'], df['m2'].size/1200)\n",
    "    x = np.append(x, _x)\n",
    "    y1 = np.append(y1, _y1)\n",
    "    y2 = np.append(y2, _y2)\n",
    "    \n",
    "x = (x-x[0])/(3600*24)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_name = 'fig_run1_track'\n",
    "\n",
    "fig5, axs5 = plt.subplots(2, 2)\n",
    "\n",
    "axs5[0,0].plot(x, y1 + 61.74e6, '.', ms=4)\n",
    "axs5[0,0].set_xlim([0,21.9])\n",
    "axs5[0,0].set_ylim([1700 + 61.79e6,2100 + 61.79e6])\n",
    "axs5[0,1].plot(x, y1 + 61.74e6 - 61.79e6, '.', ms=4, label='dipole')\n",
    "axs5[0,1].set_xlim([48.1,70])\n",
    "axs5[0,1].set_ylim([1700,2100])\n",
    "\n",
    "axs5[0,0].spines['right'].set_visible(False)\n",
    "axs5[0,1].spines['left'].set_visible(False)\n",
    "axs5[0,0].tick_params(which='both', right=False, labelbottom=False)\n",
    "axs5[0,1].tick_params(which='both', left=False, labelleft=False, labelbottom=False)\n",
    "\n",
    "axs5[1,0].plot(x, y2, '.', ms=4, color='C1')\n",
    "axs5[1,0].set_xlim([0,21.9])\n",
    "axs5[1,1].plot(x, y2, '.', ms=4, label='n quad', color='C1')\n",
    "axs5[1,1].set_xlim([48.1,70])\n",
    "\n",
    "axs5[1,0].spines['right'].set_visible(False)\n",
    "axs5[1,1].spines['left'].set_visible(False)\n",
    "axs5[1,0].tick_params(which='both', right=False)\n",
    "axs5[1,1].tick_params(which='both', left=False, labelleft=False)\n",
    "\n",
    "axs5[0,1].legend()\n",
    "axs5[1,1].legend()\n",
    "\n",
    "fig5.text(0, 0.5, 'NMR freq (Hz)', va='center', rotation='vertical')\n",
    "fig5.text(0.5, 0, 'Time (days)', ha='center')\n",
    "\n",
    "\n",
    "d = .02  # how big to make the diagonal lines in axes coordinates\n",
    "# arguments to pass to plot, just so we don't keep repeating them\n",
    "kwargs = dict(transform=axs5[0,0].transAxes, color='k', clip_on=False)\n",
    "axs5[0,0].plot((1-d, 1+d), (1-2*d, 1+2*d), **kwargs)        # top-left diagonal\n",
    "axs5[0,0].plot((1-d, 1+d), (-2*d, 2*d), **kwargs)  # botton-left diagonal\n",
    "\n",
    "kwargs = dict(transform=axs5[1,0].transAxes, color='k', clip_on=False)\n",
    "axs5[1,0].plot((1-d, 1+d), (1-2*d, 1+2*d), **kwargs)        # top-left diagonal\n",
    "axs5[1,0].plot((1-d, 1+d), (-2*d, 2*d), **kwargs)  # botton-left diagonal\n",
    "\n",
    "kwargs = dict(transform=axs5[0,1].transAxes, color='k', clip_on=False)\n",
    "axs5[0,1].plot((-d, d), (1-2*d, 1+2*d), **kwargs)        # top-right diagonal\n",
    "axs5[0,1].plot((-d, d), (-2*d, 2*d), **kwargs)  # botton-right diagonal\n",
    "\n",
    "kwargs = dict(transform=axs5[1,1].transAxes, color='k', clip_on=False)\n",
    "axs5[1,1].plot((-d, d), (1-2*d, 1+2*d), **kwargs)        # top-right diagonal\n",
    "axs5[1,1].plot((-d, d), (-2*d, 2*d), **kwargs)  # botton-right diagonal\n",
    "\n",
    "\n",
    "fig5.set_size_inches(fig_width, 0.75*fig_width)\n",
    "fig5.tight_layout()\n",
    "\n",
    "fig5.savefig('figures/run_1/'+fig_name+'.png', dpi=300, bbox_inches='tight')\n",
    "pickle.dump(axs5, open('figures/run_1/'+fig_name+'.pickle', 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## fig:run1_map\n",
    "\n",
    "fig_name = 'fig_run1_map'\n",
    "\n",
    "df = pd.DataFrame()\n",
    "for run in map_config.subruns:\n",
    "    print run\n",
    "    _df = pd.read_hdf('/data2/aetb/2020-09-30_purcell_maps.h5', key='run_'+run)\n",
    "    _df = _df.groupby(pd.cut(_df.index.values, _df.shape[0]/1200)).mean()\n",
    "    new_index = np.arange(len(_df.index))\n",
    "    for i in range(len(_df.index)):\n",
    "        new_index[i] = _df.index[i].mid\n",
    "    _df.index = new_index\n",
    "    if run == '1a1': df = _df.copy()\n",
    "    else: df = df.append(_df)\n",
    "    \n",
    "for m in range(9):\n",
    "    stm = ['st'+str(st)+',m'+str(m+1) for st in range(72)]\n",
    "    df['m'+str(m+1)] = df[stm].multiply(weight).sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_name = 'fig_run1_map'\n",
    "\n",
    "X, Y = np.meshgrid(np.linspace(-4.75,4.75,1001), np.linspace(-4.75,4.75,1001))\n",
    "\n",
    "B = X*0\n",
    "\n",
    "for m in range(9):\n",
    "    amp = np.polyfit(df.index.values, df['m'+str(m+1)].values, 0)\n",
    "    if m == 0: amp -= 52e3\n",
    "    order = trfp.matrices._MULTIPOLE_ORDER[m]\n",
    "    skew = trfp.matrices._MULTIPOLE_SKEW[m]\n",
    "    B += trfp.matrices.__multipole(order, skew, amp, X, Y)\n",
    "\n",
    "fig6, axs6 = plt.subplots(1)\n",
    "\n",
    "map6 = axs6.contourf(X, Y, B, levels=500, cmap='viridis', vmin=-300, vmax=300)\n",
    "axs6.set_aspect('equal')\n",
    "\n",
    "axs6.add_artist(plt.Circle((0, 0), 4.5, fill=False))\n",
    "\n",
    "axs6.set_xlabel('(cm)')\n",
    "axs6.set_ylabel('(cm)')\n",
    "\n",
    "cbar6 = fig6.colorbar(map6, shrink=1, ticks=[-200, -100, 0, 100, 200])\n",
    "cbar6.set_label('NMR freq - 61.792 MHz (Hz)')\n",
    "\n",
    "fig6.set_size_inches(fig_width, .75*fig_width)\n",
    "fig6.tight_layout()\n",
    "\n",
    "fig6.savefig('figures/run_1/'+fig_name+'.png', dpi=300)\n",
    "pickle.dump(axs6, open('figures/run_1/'+fig_name+'.pickle', 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################\n",
    "### Muon weighting figures ###\n",
    "##############################\n",
    "\n",
    "data_run = '1a1'\n",
    "\n",
    "vtm_file = dist_config.config_dict[data_run][0]\n",
    "vtm_key = dist_config.config_dict[data_run][1]\n",
    "interp_file = dist_config.config_dict[data_run][2]\n",
    "interp_key_1 = dist_config.config_dict[data_run][3]\n",
    "interp_key_2 = dist_config.config_dict[data_run][4]\n",
    "gold_subruns_file = dist_config.config_dict[data_run][5]\n",
    "beam_files = dist_config.config_dict[data_run][6]\n",
    "\n",
    "weight = np.diff(trfp.geometry.STATION_BARCODE_EDGES)\n",
    "weight[2] = weight[2]+360\n",
    "weight = weight/360\n",
    "\n",
    "vtm_df = pd.read_hdf(vtm_file, key=vtm_key)\n",
    "\n",
    "tr_interp_df_1 = pd.read_hdf(interp_file, key=interp_key_1)\n",
    "t_start = np.mean(tr_interp_df_1.index.values)\n",
    "tr_interp_df_2 = pd.read_hdf(interp_file, key=interp_key_2)\n",
    "t_end = np.mean(tr_interp_df_2.index.values)\n",
    "if data_run == '1d6': t_end = np.inf  # deals with not having a closing trolley run for 1d6\n",
    "else: t_end = np.mean(tr_interp_df_2.index.values)\n",
    "\n",
    "# Import a gold subrun list\n",
    "\n",
    "subrun_df = pd.read_hdf(interp_file, key='subrun_df')\n",
    "gold_subruns = np.loadtxt(gold_subruns_file)\n",
    "gold_subruns_df = pd.DataFrame(gold_subruns.astype(int), columns=['run', 'subrun']).merge(subrun_df, on=['run', 'subrun'])\n",
    "gold_subruns_df = gold_subruns_df[(gold_subruns_df['start_gps']>=t_start) & (gold_subruns_df['end_gps']<=t_end)]\n",
    "\n",
    "# need to bin into subruns\n",
    "\n",
    "vtm_interp = interp1d(vtm_df.index, vtm_df.values, axis=0)\n",
    "times = gold_subruns_df['start_gps'].append(gold_subruns_df['end_gps'])\n",
    "\n",
    "boundary_df = pd.DataFrame(vtm_interp(times), index=times, columns=vtm_df.columns)\n",
    "\n",
    "vtm_interp_df = vtm_df.append(boundary_df).sort_index()\n",
    "\n",
    "boundary_cut = pd.IntervalIndex.from_arrays(gold_subruns_df['start_gps'], gold_subruns_df['end_gps'], closed='both')\n",
    "vtm_cut = pd.cut(vtm_interp_df.index, boundary_cut)\n",
    "\n",
    "def avg_technique(bin_):\n",
    "    numer = np.trapz(bin_, x=bin_.index.values, axis=0)\n",
    "    denom = np.max(bin_.index.values)-np.min(bin_.index.values)\n",
    "\n",
    "    return numer/denom\n",
    "\n",
    "avg_field = vtm_interp_df.groupby(vtm_cut).apply(avg_technique)\n",
    "avg_df = pd.DataFrame.from_dict(dict(zip(avg_field.index, avg_field.values)), orient='index', columns=vtm_df.columns)\n",
    "avg_df['start_gps'] = [interval[0] for interval in avg_df.index.to_tuples().values]\n",
    "avg_df['end_gps'] = [interval[1] for interval in avg_df.index.to_tuples().values]\n",
    "\n",
    "output_df = gold_subruns_df[['run', 'subrun', 'start_gps', 'end_gps', 'ctags']].copy()\n",
    "output_df = output_df.merge(avg_df, on=['start_gps', 'end_gps'])\n",
    "\n",
    "# azimuthally average the field by subrun\n",
    "for m in range(9):\n",
    "    stm_list = ['st'+str(st)+',m'+str(m+1) for st in np.arange(72)]\n",
    "    output_df['m'+str(m+1)] = output_df[stm_list].multiply(weight).sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_name = 'fig_muon_avg_time'\n",
    "\n",
    "x = (output_df['start_gps'] + output_df['end_gps']).values / 2\n",
    "x = (x - x[0])/3600\n",
    "\n",
    "y1 = output_df['ctags'].values\n",
    "y2 = output_df['m1'].values + 61.74e6\n",
    "\n",
    "fig7, axs7 = plt.subplots(2,1)\n",
    "\n",
    "axs7[0].plot(x, y1, '.', markersize=6)\n",
    "axs7[1].plot(x, y2, '.', markersize=6)\n",
    "\n",
    "axs7[0].set_ylabel('Muon Number (ctags)')\n",
    "axs7[1].set_xlabel('Time (h)')\n",
    "axs7[1].set_ylabel('Dipole Field (Hz)')\n",
    "\n",
    "fig7.set_size_inches(fig_width,1*fig_width)\n",
    "fig7.tight_layout()\n",
    "\n",
    "fig7.savefig('figures/run_1/'+fig_name+'.png', dpi=300)\n",
    "pickle.dump(axs7, open('figures/run_1/'+fig_name+'.pickle', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## fig:sample_muon_distribution\n",
    "\n",
    "fig_name = 'fig_sample_muon_dist'\n",
    "\n",
    "beam_filename = 'BeamSpot_'+str(beam_files[0][0])+'_'+str(beam_files[0][1])+'.root'\n",
    "\n",
    "_beam, beam_x, beam_y = gm2.trfp.conv.loadBeamNew(beam_filename)\n",
    "beam_x = beam_x/10\n",
    "beam_y = beam_y/10\n",
    "_beam = np.transpose(_beam)\n",
    "\n",
    "X, Y = np.meshgrid(beam_x, beam_y)\n",
    "\n",
    "fig8, axs8 = plt.subplots(1)\n",
    "\n",
    "map8 = axs8.contourf(X, Y, _beam, levels=500, cmap='viridis')\n",
    "axs8.set_aspect('equal')\n",
    "\n",
    "axs8.add_artist(plt.Circle((0, 0), 4.5, fill=False))\n",
    "\n",
    "axs8.set_xlim(-5,5)\n",
    "axs8.set_ylim(-5,5)\n",
    "axs8.set_xticks([-4, -2, 0, 2, 4])\n",
    "axs8.set_yticks([-4, -2, 0, 2, 4])\n",
    "axs8.set_xlabel('(cm)')\n",
    "axs8.set_ylabel('(cm)')\n",
    "\n",
    "cbar8 = fig8.colorbar(map8, shrink=1, ticks=[0, 25, 50, 75, 100, 125])\n",
    "# cbar6.set_label('NMR freq - 61.792 MHz (Hz)')\n",
    "\n",
    "fig8.set_size_inches(fig_width, .75*fig_width)\n",
    "fig8.tight_layout()\n",
    "\n",
    "fig8.savefig('figures/run_1/'+fig_name+'.png', dpi=300)\n",
    "pickle.dump(axs8, open('figures/run_1/'+fig_name+'.pickle', 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## fig:k_i_plot\n",
    "\n",
    "fig_name = 'fig_k_i_plot'\n",
    "\n",
    "def parameterize_beam(beam, beam_x, beam_y):\n",
    "    x, y = np.meshgrid(beam_x, beam_y)\n",
    "\n",
    "    dx = np.mean(np.diff(beam_x))\n",
    "    dy = np.mean(np.diff(beam_y))\n",
    "    \n",
    "    _MULTIPOLE_ORDER = [0, 1, 1, 2, 2, 3, 3, 4, 4, 5, 5, 6, 7, 7, 8, 10, 12]\n",
    "    _MULTIPOLE_SKEW = [0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0]\n",
    "\n",
    "    order = _MULTIPOLE_ORDER\n",
    "    skew = _MULTIPOLE_SKEW\n",
    "    multipole = trfp.matrices.__multipole\n",
    "\n",
    "    n = len(order)\n",
    "    k = np.zeros(n)\n",
    "\n",
    "    for i in range(n):\n",
    "        f = multipole(order[i], skew[i], 1, x, y)\n",
    "        k[i] = np.sum(f*beam*dx*dy)/np.sum(beam*dx*dy)\n",
    "    return k\n",
    "\n",
    "beam_avg = np.zeros([200,200])\n",
    "\n",
    "for ii in range(len(beam_files)):\n",
    "    \n",
    "    beam_filename = 'BeamSpot_'+str(beam_files[ii][0])+'_'+str(beam_files[ii][1])+'.root'\n",
    "\n",
    "    _beam, beam_x, beam_y = gm2.trfp.conv.loadBeamNew(beam_filename)\n",
    "    beam_x = beam_x/10\n",
    "    beam_y = beam_y/10\n",
    "    _beam = np.transpose(_beam)\n",
    "    beam_avg += _beam\n",
    "    \n",
    "k_avg = parameterize_beam(beam_avg, beam_x, beam_y)\n",
    "\n",
    "fig9, axs9 = plt.subplots(1)\n",
    "\n",
    "axs9.semilogy(np.arange(1, k_avg.size+1), k_avg, '.', ms=10, label='positive')\n",
    "axs9.semilogy(np.arange(1, k_avg.size+1), -k_avg, '.', ms=10, label='negative')\n",
    "axs9.legend()\n",
    "\n",
    "axs9.set_ylabel(r'Beam Parameter, $k_i$ (unitless)')\n",
    "axs9.set_xlabel('Parameter Order, i')\n",
    "\n",
    "fig9.set_size_inches(fig_width, .75*fig_width)\n",
    "fig9.tight_layout()\n",
    "\n",
    "fig9.savefig('figures/run_1/'+fig_name+'.png', dpi=300)\n",
    "pickle.dump(axs9, open('figures/run_1/'+fig_name+'.pickle', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################\n",
    "### Run 1 Final Results ###\n",
    "###########################\n",
    "\n",
    "data_file = '/data2/aetb/2020-09-30_hybrid_maps.h5'\n",
    "\n",
    "weight = (trfp.STATION_BARCODE_EDGES[1:] - trfp.STATION_BARCODE_EDGES[:-1])\n",
    "weight[2] = (weight[2] + 360)\n",
    "weight = weight/360"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Run 1A\n",
    "\n",
    "## load vtm data frame, get x, y values\n",
    "run = '1a'\n",
    "key = 'run_1a1'\n",
    "vtm_df = pd.read_hdf(data_file, key=key)[['st'+str(st)+',m'+str(m) for st in range(72) for m in range(1,10)]]\n",
    "for m in range(9):\n",
    "    stm = ['st'+str(st)+',m'+str(m+1) for st in range(72)]\n",
    "    vtm_df['m'+str(m+1)] = vtm_df[stm].multiply(weight).sum(axis=1)\n",
    "x, ys = bins(vtm_df[['m'+str(m+1) for m in range(9)]], 1000)\n",
    "\n",
    "\n",
    "## get trolley run times\n",
    "interp_file = map_config.interp_file_dict[run]\n",
    "tr_times = []\n",
    "for subrun in ['fp_df_1']:\n",
    "    for interp_key in map_config.pair_dict[run][subrun]:\n",
    "        interp_df = pd.read_hdf(interp_file, key=interp_key)\n",
    "        tr_times = tr_times + [np.mean(interp_df.index.values)]\n",
    "        \n",
    "tr_times = np.array(tr_times)\n",
    "\n",
    "x0 = np.min(tr_times)\n",
    "x_tr = (tr_times - x0)/3600\n",
    "x = (x - x0)/3600.\n",
    "\n",
    "## draw figures\n",
    "fig_name = 'fig_results_run_'\n",
    "fig_name = fig_name + run\n",
    "\n",
    "fig10, axs10 = plt.subplots(3,1, sharex=True)\n",
    "\n",
    "axs10[0].plot(x, ys[:,0] + 61.74e6, '.', ms=2, color='C0')\n",
    "y_low = np.quantile(ys[:,0] + 61.74e6, 0.1)\n",
    "y_high = np.quantile(ys[:,0] + 61.74e6, 0.9)\n",
    "y_diff = y_high - y_low\n",
    "axs10[0].set_ylim(y_low - 0.5*y_diff, y_high + 0.5*y_diff)\n",
    "ymin, ymax = axs10[0].get_ylim()\n",
    "axs10[0].vlines(x_tr, ymin, ymax, color='C3', linestyle='dashed')\n",
    "axs10[0].set_ylabel('dipole (Hz)')\n",
    "axs10[0].set_title('Run ' + run)\n",
    "\n",
    "axs10[1].plot(x, ys[:,1], '.', ms=2, color='C1')\n",
    "y_low = np.quantile(ys[:,1], 0.1)\n",
    "y_high = np.quantile(ys[:,1], 0.9)\n",
    "y_diff = y_high - y_low\n",
    "axs10[1].set_ylim(y_low - 0.5*y_diff, y_high + 0.5*y_diff)\n",
    "ymin, ymax = axs10[1].get_ylim()\n",
    "axs10[1].vlines(x_tr, ymin, ymax, color='C3', linestyle='dashed')\n",
    "axs10[1].set_ylabel('nq (Hz)')\n",
    "\n",
    "axs10[2].plot(x, ys[:,4], '.', ms=2, color='C2')\n",
    "y_low = np.quantile(ys[:,4], 0.1)\n",
    "y_high = np.quantile(ys[:,4], 0.9)\n",
    "y_diff = y_high - y_low\n",
    "axs10[2].set_ylim(y_low - 0.5*y_diff, y_high + 0.5*y_diff)\n",
    "ymin, ymax = axs10[2].get_ylim()\n",
    "axs10[2].vlines(x_tr, ymin, ymax, color='C3', linestyle='dashed')\n",
    "axs10[2].set_ylabel('ns (Hz)')\n",
    "axs10[2].set_xlabel('time (hr)')\n",
    "\n",
    "fig10.set_size_inches(2*fig_width, 1*fig_width)\n",
    "fig10.tight_layout()\n",
    "\n",
    "fig10.savefig('figures/run_1/'+fig_name+'.png', dpi=300)\n",
    "pickle.dump(axs10, open('figures/run_1/'+fig_name+'.pickle', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Run 1B\n",
    "\n",
    "## load vtm data frame, get x, y values\n",
    "run = '1b'\n",
    "key = 'run_1b1'\n",
    "vtm_df = pd.read_hdf(data_file, key=key)[['st'+str(st)+',m'+str(m) for st in range(72) for m in range(1,10)]]\n",
    "for m in range(9):\n",
    "    stm = ['st'+str(st)+',m'+str(m+1) for st in range(72)]\n",
    "    vtm_df['m'+str(m+1)] = vtm_df[stm].multiply(weight).sum(axis=1)\n",
    "x, ys = bins(vtm_df[['m'+str(m+1) for m in range(9)]], 1000)\n",
    "\n",
    "key = 'run_1b2'\n",
    "vtm_df = pd.read_hdf(data_file, key=key)[['st'+str(st)+',m'+str(m) for st in range(72) for m in range(1,10)]]\n",
    "for m in range(9):\n",
    "    stm = ['st'+str(st)+',m'+str(m+1) for st in range(72)]\n",
    "    vtm_df['m'+str(m+1)] = vtm_df[stm].multiply(weight).sum(axis=1)\n",
    "x_, ys_ = bins(vtm_df[['m'+str(m+1) for m in range(9)]], 1000)\n",
    "x = np.append(x, x_)\n",
    "ys = np.append(ys, ys_, axis=0)\n",
    "\n",
    "## get trolley run times\n",
    "interp_file = map_config.interp_file_dict[run]\n",
    "tr_times = []\n",
    "for subrun in ['fp_df_1', 'fp_df_2']:\n",
    "    for interp_key in map_config.pair_dict[run][subrun]:\n",
    "        interp_df = pd.read_hdf(interp_file, key=interp_key)\n",
    "        tr_times = tr_times + [np.mean(interp_df.index.values)]\n",
    "        \n",
    "tr_times = np.array(tr_times)\n",
    "\n",
    "x0 = np.min(tr_times)\n",
    "x_tr = (tr_times - x0)/3600\n",
    "x = (x - x0)/3600.\n",
    "\n",
    "## draw figures\n",
    "fig_name = 'fig_results_run_'\n",
    "fig_name = fig_name + run\n",
    "\n",
    "fig10, axs10 = plt.subplots(3,1, sharex=True)\n",
    "\n",
    "axs10[0].plot(x, ys[:,0] + 61.74e6, '.', ms=2, color='C0')\n",
    "y_low = np.quantile(ys[:,0] + 61.74e6, 0.1)\n",
    "y_high = np.quantile(ys[:,0] + 61.74e6, 0.9)\n",
    "y_diff = y_high - y_low\n",
    "axs10[0].set_ylim(y_low - 0.5*y_diff, y_high + 0.5*y_diff)\n",
    "ymin, ymax = axs10[0].get_ylim()\n",
    "axs10[0].vlines(x_tr, ymin, ymax, color='C3', linestyle='dashed')\n",
    "axs10[0].set_ylabel('dipole (Hz)')\n",
    "axs10[0].set_title('Run ' + run)\n",
    "\n",
    "axs10[1].plot(x, ys[:,1], '.', ms=2, color='C1')\n",
    "y_low = np.quantile(ys[:,1], 0.1)\n",
    "y_high = np.quantile(ys[:,1], 0.9)\n",
    "y_diff = y_high - y_low\n",
    "axs10[1].set_ylim(y_low - 0.5*y_diff, y_high + 0.5*y_diff)\n",
    "ymin, ymax = axs10[1].get_ylim()\n",
    "axs10[1].vlines(x_tr, ymin, ymax, color='C3', linestyle='dashed')\n",
    "axs10[1].set_ylabel('nq (Hz)')\n",
    "\n",
    "axs10[2].plot(x, ys[:,4], '.', ms=2, color='C2')\n",
    "y_low = np.quantile(ys[:,4], 0.1)\n",
    "y_high = np.quantile(ys[:,4], 0.9)\n",
    "y_diff = y_high - y_low\n",
    "axs10[2].set_ylim(y_low - 0.5*y_diff, y_high + 0.5*y_diff)\n",
    "ymin, ymax = axs10[2].get_ylim()\n",
    "axs10[2].vlines(x_tr, ymin, ymax, color='C3', linestyle='dashed')\n",
    "axs10[2].set_ylabel('ns (Hz)')\n",
    "axs10[2].set_xlabel('time (hr)')\n",
    "\n",
    "fig10.set_size_inches(2*fig_width, 1*fig_width)\n",
    "fig10.tight_layout()\n",
    "\n",
    "fig10.savefig('figures/run_1/'+fig_name+'.png', dpi=300)\n",
    "pickle.dump(axs10, open('figures/run_1/'+fig_name+'.pickle', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Run 1C\n",
    "\n",
    "## load vtm data frame, get x, y values\n",
    "run = '1c'\n",
    "key = 'run_1c1'\n",
    "vtm_df = pd.read_hdf(data_file, key=key)[['st'+str(st)+',m'+str(m) for st in range(72) for m in range(1,10)]]\n",
    "for m in range(9):\n",
    "    stm = ['st'+str(st)+',m'+str(m+1) for st in range(72)]\n",
    "    vtm_df['m'+str(m+1)] = vtm_df[stm].multiply(weight).sum(axis=1)\n",
    "x, ys = bins(vtm_df[['m'+str(m+1) for m in range(9)]], 1000)\n",
    "\n",
    "for key in ['run_1c2', 'run_1c3', 'run_1c4']:\n",
    "    vtm_df = pd.read_hdf(data_file, key=key)[['st'+str(st)+',m'+str(m) for st in range(72) for m in range(1,10)]]\n",
    "    for m in range(9):\n",
    "        stm = ['st'+str(st)+',m'+str(m+1) for st in range(72)]\n",
    "        vtm_df['m'+str(m+1)] = vtm_df[stm].multiply(weight).sum(axis=1)\n",
    "    x_, ys_ = bins(vtm_df[['m'+str(m+1) for m in range(9)]], 1000)\n",
    "    x = np.append(x, x_)\n",
    "    ys = np.append(ys, ys_, axis=0)\n",
    "\n",
    "## get trolley run times\n",
    "interp_file = map_config.interp_file_dict[run]\n",
    "tr_times = []\n",
    "for subrun in ['fp_df_1', 'fp_df_2', 'fp_df_3', 'fp_df_4']:\n",
    "    for interp_key in map_config.pair_dict[run][subrun]:\n",
    "        interp_df = pd.read_hdf(interp_file, key=interp_key)\n",
    "        tr_times = tr_times + [np.mean(interp_df.index.values)]\n",
    "        \n",
    "tr_times = np.array(tr_times)\n",
    "\n",
    "x0 = np.min(tr_times)\n",
    "x_tr = (tr_times - x0)/3600\n",
    "x = (x - x0)/3600.\n",
    "\n",
    "## draw figures\n",
    "fig_name = 'fig_results_run_'\n",
    "fig_name = fig_name + run\n",
    "\n",
    "fig10, axs10 = plt.subplots(3,1, sharex=True)\n",
    "\n",
    "axs10[0].plot(x, ys[:,0] + 61.74e6, '.', ms=2, color='C0')\n",
    "y_low = np.quantile(ys[:,0] + 61.74e6, 0.1)\n",
    "y_high = np.quantile(ys[:,0] + 61.74e6, 0.9)\n",
    "y_diff = y_high - y_low\n",
    "axs10[0].set_ylim(y_low - 0.5*y_diff, y_high + 0.5*y_diff)\n",
    "ymin, ymax = axs10[0].get_ylim()\n",
    "axs10[0].vlines(x_tr, ymin, ymax, color='C3', linestyle='dashed')\n",
    "axs10[0].set_ylabel('dipole (Hz)')\n",
    "axs10[0].set_title('Run ' + run)\n",
    "\n",
    "axs10[1].plot(x, ys[:,1], '.', ms=2, color='C1')\n",
    "y_low = np.quantile(ys[:,1], 0.1)\n",
    "y_high = np.quantile(ys[:,1], 0.9)\n",
    "y_diff = y_high - y_low\n",
    "axs10[1].set_ylim(y_low - 0.5*y_diff, y_high + 0.5*y_diff)\n",
    "ymin, ymax = axs10[1].get_ylim()\n",
    "axs10[1].vlines(x_tr, ymin, ymax, color='C3', linestyle='dashed')\n",
    "axs10[1].set_ylabel('nq (Hz)')\n",
    "\n",
    "axs10[2].plot(x, ys[:,4], '.', ms=2, color='C2')\n",
    "y_low = np.quantile(ys[:,4], 0.1)\n",
    "y_high = np.quantile(ys[:,4], 0.9)\n",
    "y_diff = y_high - y_low\n",
    "axs10[2].set_ylim(y_low - 0.5*y_diff, y_high + 0.5*y_diff)\n",
    "ymin, ymax = axs10[2].get_ylim()\n",
    "axs10[2].vlines(x_tr, ymin, ymax, color='C3', linestyle='dashed')\n",
    "axs10[2].set_ylabel('ns (Hz)')\n",
    "axs10[2].set_xlabel('time (hr)')\n",
    "\n",
    "fig10.set_size_inches(2*fig_width, 1*fig_width)\n",
    "fig10.tight_layout()\n",
    "\n",
    "fig10.savefig('figures/run_1/'+fig_name+'.png', dpi=300)\n",
    "pickle.dump(axs10, open('figures/run_1/'+fig_name+'.pickle', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Run 1D\n",
    "\n",
    "## load vtm data frame, get x, y values\n",
    "run = '1d'\n",
    "key = 'run_1d2'\n",
    "vtm_df = pd.read_hdf(data_file, key=key)[['st'+str(st)+',m'+str(m) for st in range(72) for m in range(1,10)]]\n",
    "for m in range(9):\n",
    "    stm = ['st'+str(st)+',m'+str(m+1) for st in range(72)]\n",
    "    vtm_df['m'+str(m+1)] = vtm_df[stm].multiply(weight).sum(axis=1)\n",
    "x, ys = bins(vtm_df[['m'+str(m+1) for m in range(9)]], 1000)\n",
    "\n",
    "for key in ['run_1d3', 'run_1d4', 'run_1d5', 'run_1d6']:\n",
    "    vtm_df = pd.read_hdf(data_file, key=key)[['st'+str(st)+',m'+str(m) for st in range(72) for m in range(1,10)]]\n",
    "    for m in range(9):\n",
    "        stm = ['st'+str(st)+',m'+str(m+1) for st in range(72)]\n",
    "        vtm_df['m'+str(m+1)] = vtm_df[stm].multiply(weight).sum(axis=1)\n",
    "    x_, ys_ = bins(vtm_df[['m'+str(m+1) for m in range(9)]], 1000)\n",
    "    x = np.append(x, x_)\n",
    "    ys = np.append(ys, ys_, axis=0)\n",
    "\n",
    "## get trolley run times\n",
    "interp_file = map_config.interp_file_dict[run]\n",
    "tr_times = []\n",
    "for subrun in ['fp_df_2', 'fp_df_3', 'fp_df_4', 'fp_df_5']:\n",
    "    for interp_key in map_config.pair_dict[run][subrun]:\n",
    "        interp_df = pd.read_hdf(interp_file, key=interp_key)\n",
    "        tr_times = tr_times + [np.mean(interp_df.index.values)]\n",
    "        \n",
    "tr_times = np.array(tr_times)\n",
    "\n",
    "x0 = np.min(tr_times)\n",
    "x_tr = (tr_times - x0)/3600\n",
    "x = (x - x0)/3600.\n",
    "\n",
    "## draw figures\n",
    "fig_name = 'fig_results_run_'\n",
    "fig_name = fig_name + run\n",
    "\n",
    "fig10, axs10 = plt.subplots(3,1, sharex=True)\n",
    "\n",
    "axs10[0].plot(x, ys[:,0] + 61.74e6, '.', ms=2, color='C0')\n",
    "y_low = np.quantile(ys[:,0] + 61.74e6, 0.1)\n",
    "y_high = np.quantile(ys[:,0] + 61.74e6, 0.9)\n",
    "y_diff = y_high - y_low\n",
    "axs10[0].set_ylim(y_low - 0.5*y_diff, y_high + 0.5*y_diff)\n",
    "ymin, ymax = axs10[0].get_ylim()\n",
    "axs10[0].vlines(x_tr, ymin, ymax, color='C3', linestyle='dashed')\n",
    "axs10[0].set_ylabel('dipole (Hz)')\n",
    "axs10[0].set_title('Run ' + run)\n",
    "\n",
    "axs10[1].plot(x, ys[:,1], '.', ms=2, color='C1')\n",
    "y_low = np.quantile(ys[:,1], 0.1)\n",
    "y_high = np.quantile(ys[:,1], 0.9)\n",
    "y_diff = y_high - y_low\n",
    "axs10[1].set_ylim(y_low - 0.5*y_diff, y_high + 0.5*y_diff)\n",
    "ymin, ymax = axs10[1].get_ylim()\n",
    "axs10[1].vlines(x_tr, ymin, ymax, color='C3', linestyle='dashed')\n",
    "axs10[1].set_ylabel('nq (Hz)')\n",
    "\n",
    "axs10[2].plot(x, ys[:,4], '.', ms=2, color='C2')\n",
    "y_low = np.quantile(ys[:,4], 0.1)\n",
    "y_high = np.quantile(ys[:,4], 0.9)\n",
    "y_diff = y_high - y_low\n",
    "axs10[2].set_ylim(y_low - 0.5*y_diff, y_high + 0.5*y_diff)\n",
    "ymin, ymax = axs10[2].get_ylim()\n",
    "axs10[2].vlines(x_tr, ymin, ymax, color='C3', linestyle='dashed')\n",
    "axs10[2].set_ylabel('ns (Hz)')\n",
    "axs10[2].set_xlabel('time (hr)')\n",
    "\n",
    "fig10.set_size_inches(2*fig_width, 1*fig_width)\n",
    "fig10.tight_layout()\n",
    "\n",
    "fig10.savefig('figures/run_1/'+fig_name+'.png', dpi=300)\n",
    "pickle.dump(axs10, open('figures/run_1/'+fig_name+'.pickle', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## sextupole aliasing figure\n",
    "\n",
    "fig_name = 'fig_sext_alias'\n",
    "\n",
    "multipole = trfp.matrices.__multipole\n",
    "\n",
    "X, Y = np.meshgrid(np.linspace(-4.75,4.75,1001), np.linspace(-8,8,1001))\n",
    "\n",
    "B = trfp.matrices.__multipole(2, 0, 1, X, Y)\n",
    "\n",
    "fig11, axs11 = plt.subplots(1)\n",
    "\n",
    "map11 = axs11.contourf(X, Y, B, levels=500, cmap='viridis')\n",
    "# axs11.set_aspect('equal')\n",
    "\n",
    "axs11.plot(trfp.geometry.FP6_X, trfp.geometry.FP6_Y, '.', ms=20, color='C1')\n",
    "\n",
    "axs11.add_artist(plt.Circle((0, 0), 4.5, fill=False))\n",
    "\n",
    "axs11.set_xlabel('(cm)')\n",
    "axs11.set_ylabel('(cm)')\n",
    "\n",
    "axs11.set_xticks([-4, -2, 0, 2, 4])\n",
    "\n",
    "fig11.set_size_inches(fig_width, fig_width)\n",
    "fig11.tight_layout()\n",
    "\n",
    "fig11.savefig('figures/run_1/'+fig_name+'.png', dpi=300)\n",
    "pickle.dump(axs11, open('figures/run_1/'+fig_name+'.pickle', 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
