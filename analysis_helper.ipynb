{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis Helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.integrate import cumtrapz\n",
    "\n",
    "import gm2\n",
    "import trfp\n",
    "import helper_function_candidates as helper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert Tier-1 ROOT files to Pandas data frames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function takes a list of run numbers and uses S. Corrodi's gm2 module to read the ROOT files.\n",
    "It then performs the event-wise DQC cuts and time-grid interpolation.\n",
    "It outputs a standard Pandas data frame."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Short helper functions\n",
    "`_nan_helper`\n",
    "\n",
    "`_choose_J`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _nan_helper(y):\n",
    "    \"\"\"Helper to handle indices and logical indices of NaNs.\n",
    "\n",
    "    Input:\n",
    "        - y, 1d numpy array with possible NaNs\n",
    "    Output:\n",
    "        - nans, logical indices of NaNs\n",
    "        - index, a function, with signature indices= index(logical_indices),\n",
    "          to convert logical indices of NaNs to 'equivalent' indices\n",
    "    Example:\n",
    "        >>> # linear interpolation of NaNs\n",
    "        >>> nans, index= nan_helper(y)\n",
    "        >>> y[nans]= np.interp(index(nans), index(~nans), y[~nans])\n",
    "    \"\"\"\n",
    "\n",
    "    return np.isnan(y), lambda z: z.nonzero()[0]\n",
    "\n",
    "def _choose_J(st):\n",
    "    if trfp.STATION_PROBE_NUMBER[st] == 4:\n",
    "        if st == 41: J = trfp.J_4_PROBE_ST41\n",
    "        elif (st == 37) | (st == 39): J = trfp.J_4_PROBE_ST37_ST39\n",
    "        else: J = trfp.J_4_PROBE\n",
    "    elif trfp.STATION_PROBE_NUMBER[st] == 6:\n",
    "        if st < 6: J = trfp.J_6_PROBE_OFFSET\n",
    "        else: J = trfp.J_6_PROBE\n",
    "    else:\n",
    "        raise Exception('Invalid number of station probes.')\n",
    "    return J\n",
    "\n",
    "def _choose_theta(st):\n",
    "    if trfp.STATION_PROBE_NUMBER[st] == 4:\n",
    "        if st == 41:\n",
    "            theta_fp = trfp.THETA_FP_4_ST41\n",
    "        elif (st == 37) | (st == 39):\n",
    "            theta_fp = trfp.THETA_FP_4_ST37_ST39\n",
    "        else:\n",
    "            theta_fp = trfp.THETA_FP_4\n",
    "    elif trfp.STATION_PROBE_NUMBER[st] == 6:\n",
    "        theta_fp = trfp.THETA_FP_6\n",
    "    else:\n",
    "        raise Exception('Invalid number of station probes.')\n",
    "    return theta_fp\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Root to interpolated data frame\n",
    "`root_to_pandas`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def root_to_pandas(run_range, prefix=None, tr_run=False):\n",
    "    \n",
    "    if len(run_range) == 0: raise Exception('No runs specified.')\n",
    "    if tr_run and len(run_range) > 1: raise Exception('Only one trolley run can be processed at a time.')\n",
    "    if tr_run:\n",
    "        tr_run = gm2.Trolley(run_range, prefix=prefix)\n",
    "        if tr_run.getEntries() == 0: raise Exception('No trolley events.')\n",
    "    fp_run = gm2.FixedProbe(run_range, prefix=prefix)\n",
    "    \n",
    "    if tr_run:\n",
    "        tr_time, tr_phi, tr_freq = tr_run.getBasics()\n",
    "        # drop first 5 events, which are 0, and last event, which can some times be 0\n",
    "        tr_time = tr_time[5:-1,:]/1.0e9  # convert nsec to sec\n",
    "        tr_phi = tr_phi[5:-1,:]\n",
    "        tr_freq = tr_freq[5:-1,:]\n",
    "        for tr in range(17):\n",
    "            tr_freq[:, tr] += trfp.PLUNGING_PROBE_CALIBRATIONS[tr]\n",
    "\n",
    "    fp_time, fp_freq, fp_qual = fp_run.getBasics()\n",
    "    # drop first event, which is always 0 from import\n",
    "    fp_time = fp_time[1:,:]/1.0e9  # convert nsec to sec\n",
    "    fp_freq = fp_freq[1:,:]\n",
    "    fp_qual = fp_qual[1:,:]\n",
    "\n",
    "    ################################################################################\n",
    "    ### Apply fixed probe event DQC cuts ###########################################\n",
    "    ################################################################################\n",
    "    \n",
    "    # remove the 8th bit and 16th bit flags (Ran's flags?)\n",
    "    fp_qual[fp_qual >= 2**16] -= 2**16\n",
    "    fp_qual[fp_qual >= 2**8] -= 2**8\n",
    "\n",
    "    fp_freq_dqc = fp_freq.copy()\n",
    "    fp_freq_dqc[fp_qual > 0] = np.nan\n",
    "\n",
    "    for fp in range(378):\n",
    "        nans, index = _nan_helper(fp_freq_dqc[:,fp])\n",
    "        fp_freq_dqc[:,fp][nans] = np.interp(index(nans), index(~nans), fp_freq_dqc[:,fp][~nans])\n",
    "\n",
    "    ################################################################################\n",
    "    ################################################################################\n",
    "    ################################################################################\n",
    "\n",
    "\n",
    "    # first, need to make array of raw times, grid times, and grid time edges\n",
    "    # then find the index of each grid time point in that sorted array\n",
    "\n",
    "    ################################################################################\n",
    "    ### Trolley Runs ###############################################################\n",
    "    ################################################################################\n",
    "    if tr_run:\n",
    "        grid_times = np.arange(np.ceil(np.max(tr_time[0,:])),\n",
    "                               np.floor(np.min(tr_time[-1,:]))+1,\n",
    "                               1.0)\n",
    "        edge_times = np.arange(grid_times[0]-0.5, grid_times[-1]+1.5, 1.0)\n",
    "        grid_phi = np.empty([grid_times.size, 1])\n",
    "        grid_tr_freqs = np.empty([grid_times.size, 17])\n",
    "        grid_freqs = np.empty([grid_times.size, 378])\n",
    "   \n",
    "\n",
    "        ################################################################################\n",
    "        ### Interpolate trolley position ###############################################\n",
    "        ################################################################################\n",
    "\n",
    "        phi_time = np.mean(tr_time, axis=1)\n",
    "        phi_phi = np.mean(tr_phi, axis=1)\n",
    "        \n",
    "        all_times = np.append(edge_times,phi_time)\n",
    "        sort_index = np.argsort(all_times)\n",
    "        unsort_index = np.argsort(sort_index)\n",
    "        edge_index = unsort_index[0:len(grid_times)+1]\n",
    "        \n",
    "        edge_phi = np.interp(edge_times, phi_time, phi_phi)\n",
    "        all_phi = np.append(edge_phi, phi_phi)\n",
    "        sort_phi = all_phi[sort_index]\n",
    "        sort_times = all_times[sort_index]\n",
    "        \n",
    "        integrated_phi = cumtrapz(sort_phi, x=sort_times, initial=0)\n",
    "        grid_phi[:,0] = np.diff(integrated_phi[edge_index])\n",
    "\n",
    "        ################################################################################\n",
    "        ################################################################################\n",
    "        ################################################################################\n",
    "        \n",
    "        for tr in range(17):\n",
    "            all_times = np.append(edge_times, tr_time[:,tr])\n",
    "\n",
    "            sort_index = np.argsort(all_times)\n",
    "            unsort_index = np.argsort(sort_index)\n",
    "            edge_index = unsort_index[0:len(grid_times)+1]\n",
    "\n",
    "            # interpolate the freqs on the time grid edges\n",
    "            edge_freqs = np.interp(edge_times, tr_time[:,tr], tr_freq[:,tr])\n",
    "\n",
    "            # sort all times and all freqs by method calculated above\n",
    "            all_freqs = np.append(edge_freqs, tr_freq[:,tr])\n",
    "            sort_freqs = all_freqs[sort_index]\n",
    "            sort_times = all_times[sort_index]\n",
    "\n",
    "            # run cumtrapz on sorted times and freqs\n",
    "            integrated_freqs = cumtrapz(sort_freqs, x=sort_times, initial=0)\n",
    "\n",
    "            # take differences of the integrated freqs at grid edge points\n",
    "            # to find the integral between the two points\n",
    "\n",
    "            grid_tr_freqs[:,tr] = np.diff(integrated_freqs[edge_index])\n",
    "        \n",
    "\n",
    "        for fp in range(378):\n",
    "            all_times = np.append(edge_times,fp_time[:,fp])\n",
    "\n",
    "            sort_index = np.argsort(all_times)\n",
    "            unsort_index = np.argsort(sort_index)\n",
    "            edge_index = unsort_index[0:len(grid_times)+1]\n",
    "\n",
    "            # interpolate the freqs on the time grid edges\n",
    "            edge_freqs = np.interp(edge_times, fp_time[:,fp], fp_freq_dqc[:,fp])\n",
    "\n",
    "            # sort all times and all freqs by method calculated above\n",
    "            all_freqs = np.append(edge_freqs, fp_freq_dqc[:,fp])\n",
    "            sort_freqs = all_freqs[sort_index]\n",
    "            sort_times = all_times[sort_index]\n",
    "\n",
    "            # run cumtrapz on sorted times and freqs\n",
    "            integrated_freqs = cumtrapz(sort_freqs, x=sort_times, initial=0)\n",
    "\n",
    "            # take differences of the integrated freqs at grid edge points\n",
    "            # to find the integral between the two points\n",
    "\n",
    "            grid_freqs[:,fp] = np.diff(integrated_freqs[edge_index])\n",
    "        \n",
    "        cols = [\"tr_phi\"] + [\"tr\" + str(i) for i in np.arange(17)] + [\"fp\" + str(i) for i in np.arange(378)]\n",
    "        data = np.append(grid_phi, np.append(grid_tr_freqs, grid_freqs, axis=1), axis=1)\n",
    "        \n",
    "    ################################################################################\n",
    "    ### Fixed Probe Runs ###########################################################\n",
    "    ################################################################################\n",
    "    else:\n",
    "        grid_times = np.arange(np.ceil(np.max(fp_time[0,:])),\n",
    "                               np.floor(np.min(fp_time[-1,:]))+1,\n",
    "                               1.0)\n",
    "        edge_times = np.arange(grid_times[0]-0.5, grid_times[-1]+1.5, 1.0)\n",
    "        grid_freqs = np.empty([grid_times.size, 378])\n",
    "\n",
    "        for fp in range(378):\n",
    "            all_times = np.append(edge_times,fp_time[:,fp])\n",
    "\n",
    "            sort_index = np.argsort(all_times)\n",
    "            unsort_index = np.argsort(sort_index)\n",
    "            edge_index = unsort_index[0:len(grid_times)+1]\n",
    "\n",
    "            # interpolate the freqs on the time grid edges\n",
    "            edge_freqs = np.interp(edge_times, fp_time[:,fp], fp_freq_dqc[:,fp])\n",
    "\n",
    "            # sort all times and all freqs by method calculated above\n",
    "            all_freqs = np.append(edge_freqs, fp_freq_dqc[:,fp])\n",
    "            sort_freqs = all_freqs[sort_index]\n",
    "            sort_times = all_times[sort_index]\n",
    "\n",
    "            # run cumtrapz on sorted times and freqs\n",
    "            integrated_freqs = cumtrapz(sort_freqs, x=sort_times, initial=0)\n",
    "\n",
    "            # take differences of the integrated freqs at grid edge points\n",
    "            # to find the integral between the two points\n",
    "\n",
    "            grid_freqs[:,fp] = np.diff(integrated_freqs[edge_index])\n",
    "            \n",
    "        data = grid_freqs\n",
    "        cols = [\"fp\" + str(i) for i in np.arange(378)]\n",
    "\n",
    "    return pd.DataFrame(data, index=grid_times, columns=cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpolated data frame to moment data frame\n",
    "`calc_moment_df`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_moment_df(interp_df):\n",
    "    \n",
    "    tr_run = 'tr_phi' in interp_df.columns\n",
    "    \n",
    "    moment_df = pd.DataFrame(index=interp_df.index)\n",
    "    \n",
    "    # calculate trolley moments if needed\n",
    "    if tr_run:\n",
    "        moment_df['tr_phi'] = interp_df['tr_phi'].copy()\n",
    "        print 'Calculating trolley moments.',\n",
    "        theta_tr = trfp.THETA_TR\n",
    "        for m in np.arange(17):\n",
    "            tr_probes = ['tr'+str(probe) for probe in np.arange(17)]\n",
    "            moment_df['tr,m'+str(m+1)] = interp_df[tr_probes].dot(theta_tr[m])\n",
    "\n",
    "    # create the 72*6 fixed probe moments\n",
    "    for station in np.arange(72):\n",
    "        print '\\rCalculating station ' + str(station) + ' moments.',\n",
    "        fp_st = ['fp'+str(fp) for fp in trfp.STATION_PROBE_ID[station]]\n",
    "\n",
    "        # choose proper theta matrix\n",
    "        theta_fp = _choose_theta(station)\n",
    "\n",
    "        # step through m values\n",
    "        for m in np.arange(len(trfp.STATION_PROBE_ID[station])):\n",
    "            stm = 'st'+str(station)+',m'+str(m+1)\n",
    "            moment_df[stm] = interp_df[fp_st].dot(theta_fp[m])\n",
    "        if len(trfp.STATION_PROBE_ID[station]) == 4:\n",
    "            moment_df['st'+str(station)+',m5'] = np.nan\n",
    "            moment_df['st'+str(station)+',m6'] = np.nan\n",
    "\n",
    "    # Interpolate the 6-probe m5 and m6 into the 4-probe m5 and m6        \n",
    "    for st in range(72):\n",
    "        if trfp.STATION_PROBE_NUMBER[st] == 4:\n",
    "            wt = trfp.STATION_BARCODE_PHI[(st+1)%72] - trfp.STATION_BARCODE_PHI[(st-1)%72]\n",
    "            w1 = trfp.STATION_BARCODE_PHI[(st+1)%72] - trfp.STATION_BARCODE_PHI[st]\n",
    "            w2 = trfp.STATION_BARCODE_PHI[st] - trfp.STATION_BARCODE_PHI[(st-1)%72]\n",
    "\n",
    "            for m in [5, 6]:\n",
    "                stm = 'st'+str(st)+',m'+str(m)\n",
    "                if not np.isnan(moment_df[stm].iloc[0]):\n",
    "                    print stm + ' is not nan.'\n",
    "                    continue\n",
    "                stm1 = 'st'+str((st-1)%72)+',m'+str(m)\n",
    "                stm2 = 'st'+str((st+1)%72)+',m'+str(m)\n",
    "\n",
    "                moment_df[stm] = (w1*moment_df[stm1] + w2*moment_df[stm2])/wt\n",
    "\n",
    "    print '\\rFinished calculating all moments for ' + str(moment_df.shape[0]) + ' events.'\n",
    "    \n",
    "    return moment_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Virtual trolley measurement calculation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`vtm_calc`\n",
    "\n",
    "$m_{vtr}(t) = m_{tr}(0) + J\\left[m_{fp}(t) - m_{fp}(0)\\right]$\n",
    "\n",
    "$m_{vtr}(t) = J m_{fp}(t) + \\left[m_{tr}(0) - J m_{fp}(0)\\right]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate virutal trolley measurements\n",
    "\n",
    "def vtm_calc(fp_moment_df,\n",
    "             baseline_time_1, baseline_time_2,\n",
    "             tr_baseline_1, tr_baseline_2,\n",
    "             fp_baseline_1, fp_baseline_2):\n",
    "    \n",
    "    vtm_df = fp_moment_df.copy()\n",
    "    \n",
    "    # apply Jacobian to each station's m_fp\n",
    "    \n",
    "    for st in range(72):\n",
    "        \n",
    "        # choose Jacobian\n",
    "        J = _choose_J(st)\n",
    "                \n",
    "        # apply Jacobian to each station's m_fp\n",
    "        stms = ['st'+str(st)+',m'+str(m+1) for m in range(5)]\n",
    "        vtm_df[stms] = vtm_df[stms].dot(np.transpose(J))\n",
    "    \n",
    "        # apply sync correction (m_tr(0) - J*m_fp(0)), interpolated\n",
    "        \n",
    "        sync_correction_1 = tr_baseline_1[st,0:5] - np.matmul(J, fp_baseline_1[st,0:5])\n",
    "        sync_correction_2 = tr_baseline_2[st,0:5] - np.matmul(J, fp_baseline_2[st,0:5])\n",
    "        \n",
    "        sync_correction = np.empty((len(vtm_df.index.values),5))\n",
    "        for m in range(5):\n",
    "            sync_correction[:,m] = np.interp(vtm_df.index.values,\n",
    "                                             [baseline_time_1[st,m], baseline_time_2[st,m]],\n",
    "                                             [sync_correction_1[m], sync_correction_2[m]])\n",
    "        vtm_df[stms] += sync_correction\n",
    "        \n",
    "    return vtm_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trolley footprint removal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove the trolley footprint from the fixed probe meaurements by vetoing a window when the trolley is near the fixed probe station and replacing the vetoed section with a drift-corrected average from the rest of the ring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trolley run station averaging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions that average trolley moments over azimuth and corrected fixed probe moments over time. Two seprate averaging modes: boxcar and triangular.\n",
    "\n",
    "NOTE: more work is needed to determine how to applying triangular averaging to fixed probe time average."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sync offset calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sync_offset_calc(tr_corr_df_1, tr_corr_df_2):\n",
    "    tr_baseline_1, fp_baseline_1, baseline_time_1, _, _ = helper.trolley_run_station_average(tr_corr_df_1)\n",
    "    tr_baseline_2, fp_baseline_2, baseline_time_2, _, _ = helper.trolley_run_station_average(tr_corr_df_2)\n",
    "    delta_time = baseline_time_2 - baseline_time_1\n",
    "    \n",
    "    delta_tr_baseline = tr_baseline_2 - tr_baseline_1\n",
    "    delta_fp_baseline = fp_baseline_2 - fp_baseline_1\n",
    "    \n",
    "    sync_offsets = np.empty((72,5))\n",
    "    for st in range(72):\n",
    "        J = _choose_J(st)\n",
    "#         sync_offsets[st,:] = delta_tr_baseline[st,:-1] - delta_fp_baseline[st,:-1]\n",
    "        sync_offsets[st,:] = delta_tr_baseline[st,:-1] -  np.matmul(J, delta_fp_baseline[st,:-1])\n",
    "    \n",
    "    return sync_offsets, delta_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp_interp_df = root_to_pandas(range(3960,3995), prefix='v9_21_03_dev/FieldPlainRootOutput_', tr_run=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_interp_df_1 = root_to_pandas([3956], prefix='v9_21_03_dev/FieldPlainRootOutput_', tr_run=True)\n",
    "tr_interp_df_2 = root_to_pandas([3997], prefix='v9_21_03_dev/FieldPlainRootOutput_', tr_run=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp_moment_df = calc_moment_df(fp_interp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_moment_df_1 = calc_moment_df(tr_interp_df_1)\n",
    "tr_moment_df_2 = calc_moment_df(tr_interp_df_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_corr_df_1 = trfp.analysis.remove_trolley_effect(tr_moment_df_1)\n",
    "tr_corr_df_2 = trfp.analysis.remove_trolley_effect(tr_moment_df_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_baseline_1, fp_baseline_1, baseline_time_1, _, _ = helper.trolley_run_station_average(tr_corr_df_1)\n",
    "tr_baseline_2, fp_baseline_2, baseline_time_2, _, _ = helper.trolley_run_station_average(tr_corr_df_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vtm_df = vtm_calc(fp_moment_df,\n",
    "                  baseline_time_1, baseline_time_2,\n",
    "                  tr_baseline_1, tr_baseline_2,\n",
    "                  fp_baseline_1, fp_baseline_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print tr_baseline_1[41,0]\n",
    "print tr_baseline_2[41,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(vtm_df.index.values, vtm_df['st41,m1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(vtm_df.index.values, vtm_df['st41,m5'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print baseline_time[:,4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Bin into the agreed upon bins\n",
    "\n",
    "bins = np.arange(1524384055, 1524641055, 1000)-500  # bin edges\n",
    "bin_centers = np.arange(1524384055, 1524640055, 1000)\n",
    "\n",
    "vtm_bin_df = vtm_df.groupby(pd.cut(vtm_df.index, bins)).mean()\n",
    "vtm_bin_df.index = bin_centers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotting_functions as plt2\n",
    "\n",
    "fig, axs = plt.subplots(24,3)\n",
    "\n",
    "for i in range(24):\n",
    "    for j in range(3):\n",
    "        plt.sca(axs[i,j])\n",
    "        st = i*3 + j\n",
    "        plt.plot(vtm_bin_df.index.values, vtm_bin_df['st'+str(st)+',m1'], '.', markersize=1, color='navy')\n",
    "        plt2.plt_set_labels(axs[i,j], '', 'N dipole (ppm)', 'st '+str(st))\n",
    "        plt2.plt_unix_time_to_CST(axs[i,j])\n",
    "\n",
    "fig.set_size_inches(16, 80)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
