{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.optimize import curve_fit\n",
    "import scipy\n",
    "\n",
    "#import gm2\n",
    "import trfp\n",
    "import plotting_functions as plt2\n",
    "import analysis_helper as helper\n",
    "import helper_function_candidates as helper_old\n",
    "\n",
    "#import mu_avg.mu_avg as mu_avg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data, calculate vtms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "# fp_interp_df = helper.root_to_pandas(range(3959,3995), prefix='data1/newg2/DataProduction/Offline/ArtTFSDir/v9_20_00/FieldPlainRootOutput_', tr_run=False)\n",
    "# tr_interp_df_1 = helper.root_to_pandas([3956], prefix='data1/newg2/DataProduction/Offline/ArtTFSDir/v9_20_00/FieldPlainRootOutput_', tr_run=True)\n",
    "# tr_interp_df_2 = helper.root_to_pandas([3997], prefix='data1/newg2/DataProduction/Offline/ArtTFSDir/v9_20_00/FieldPlainRootOutput_', tr_run=True)\n",
    "\n",
    "filename = 'hdf5/60hr.h5'\n",
    "\n",
    "fp_interp_df = pd.read_hdf(filename, key='fp_df_1')\n",
    "tr_interp_df_1 = pd.read_hdf(filename, key='tr_df_1')\n",
    "tr_interp_df_2 = pd.read_hdf(filename, key='tr_df_2')\n",
    "########################\n",
    "#fp_interp_df.head()\n",
    "tr_interp_df_1.head(3170)\n",
    "x = np.array(tr_interp_df_1[\"tr_phi\"])\n",
    "print(x)\n",
    "y = np.array(tr_interp_df_1[\"fp370\"])\n",
    "plt.plot(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(tr_interp_df_1.index.values, tr_interp_df_1[\"fp370\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "fp_moment_df = helper.calc_moment_df(fp_interp_df)\n",
    "tr_moment_df_1 = helper.calc_moment_df(tr_interp_df_1)\n",
    "tr_moment_df_2 = helper.calc_moment_df(tr_interp_df_2)\n",
    "##############################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_moment_df_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "tr_corr_df_1 = helper_old.trolley_footprint_replacement(tr_moment_df_1)\n",
    "tr_corr_df_2 = helper_old.trolley_footprint_replacement(tr_moment_df_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tr_corr_df_1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### aside for sync offset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sync_offsets, delta_time = helper.sync_offset_calc(tr_corr_df_1, tr_corr_df_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sync_offsets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print np.mean(sync_offsets[:,0])\n",
    "print np.std(sync_offsets[:,0])\n",
    "\n",
    "print np.std(sync_offsets[:,0])/np.sqrt(72)/61.79*1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fig1, ax1 = plt.subplots(1,1)\n",
    "\n",
    "m=3\n",
    "\n",
    "out = ax1.hist(sync_offsets[:,m-1], bins=40)\n",
    "def gaussian(x, A, x0, s): return A * np.exp(-(x-x0)**2/(2*s**2))\n",
    "counts = out[0]\n",
    "bins = (out[1][1:]+out[1][:-1])/2\n",
    "fit, _ = curve_fit(gaussian, bins, counts, p0=(20,-10,75))\n",
    "\n",
    "ax1.plot(np.linspace(-200,200,1000), gaussian(np.linspace(-200,200,1000), *fit),\n",
    "         label=('$\\mu$ = %.1e \\n $\\sigma$ = %.1e'%(fit[1],fit[2])))\n",
    "\n",
    "ax1.legend(prop={'size':10, 'family':'serif'})\n",
    "\n",
    "ax1.set_title('$m_1$ Sync Offsets', fontdict={'size':12, 'family':'serif'})\n",
    "ax1.set_xlabel('sync offset (Hz)', fontdict={'size':12, 'family':'serif'})\n",
    "ax1.set_ylabel('counts', fontdict={'size':12, 'family':'serif'})\n",
    "\n",
    "# ax1.set_xlim(-200,200)\n",
    "\n",
    "fig1.set_size_inches(6,4)\n",
    "fig1.tight_layout()\n",
    "\n",
    "# fig1.savefig('sync_offsets.png', dpi=300)\n",
    "\n",
    "print fit[2]/2\n",
    "print fit[2]/2/61.79*1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  back to calc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "tr_baseline_1, fp_baseline_1, baseline_time_1, summed_azimuth_1, summed_pts_1 = helper_old.trolley_run_station_average(tr_corr_df_1)\n",
    "tr_baseline_2, fp_baseline_2, baseline_time_2, summed_azimuth_2, summed_pts_2 = helper_old.trolley_run_station_average(tr_corr_df_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "vtm_df = helper.vtm_calc(fp_moment_df,\n",
    "                         baseline_time_1, baseline_time_2,\n",
    "                         tr_baseline_1, tr_baseline_2,\n",
    "                         fp_baseline_1, fp_baseline_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vtm_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Bin into the agreed upon bins\n",
    "\n",
    "bins = np.arange(1524384055, 1524639055+200, 100)-50  # bin edges\n",
    "bin_centers = np.arange(1524384055, 1524639055+100, 100)\n",
    "\n",
    "vtm_bin_df = vtm_df.groupby(pd.cut(vtm_df.index, bins)).mean()\n",
    "vtm_bin_df.index = bin_centers\n",
    "\n",
    "test_df = vtm_bin_df.copy()\n",
    "\n",
    "azi_avg_df = pd.DataFrame(np.zeros((vtm_bin_df.shape[0],6)),\n",
    "                         index = vtm_bin_df.index,\n",
    "                         columns = ['m' + str(m) for m in np.arange(6)+1])\n",
    "\n",
    "for m in range(5):\n",
    "    weight = (summed_azimuth_1[:, m] + summed_azimuth_2[:, m])\n",
    "    total_weight = np.nansum(weight)\n",
    "    stm_list = ['st'+str(st)+',m'+str(m+1) for st in np.arange(72)]\n",
    "    azi_avg_df['m'+str(m+1)] = vtm_bin_df[stm_list].multiply(weight).sum(axis=1)/total_weight\n",
    "print_df = azi_avg_df[['m1','m2','m3','m4','m5']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vtm_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plt_unix_time_to_CST(ax):\n",
    "    ax.locator_params(axis='x', nbins=5)\n",
    "    xticks = ax.get_xticks()\n",
    "    ax.set_xticklabels([pd.to_datetime(tm, unit='s').tz_localize('UTC').tz_convert('US/Central').strftime('%Y-%m-%d\\n %H:%M:%S %Z')\n",
    "                        for tm in xticks], rotation=0, fontdict={'size':12, 'family':'serif'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style('darkgrid')\n",
    "\n",
    "fig2, ax2 = plt.subplots(1,1)\n",
    "m = 1\n",
    "ax2.plot(print_df.index.values, print_df['m'+str(m)], '.')\n",
    "ax2.set_ylabel('$m_'+str(m)+'$-61.74 MHz (Hz)', fontdict={'size':12, 'family':'serif'})\n",
    "plt_unix_time_to_CST(ax2)\n",
    "fig2.set_size_inches(6,3)\n",
    "fig2.tight_layout()\n",
    "# fig2.savefig('60hr_m'+str(m)+'.png', dpi=300)\n",
    "\n",
    "\n",
    "fig3, ax3 = plt.subplots(1,1)\n",
    "m = 2\n",
    "ax3.plot(print_df.index.values, print_df['m'+str(m)], '.')\n",
    "ax3.set_ylabel('$m_'+str(m)+'$ (Hz)', fontdict={'size':12, 'family':'serif'})\n",
    "plt_unix_time_to_CST(ax3)\n",
    "fig3.set_size_inches(6,3)\n",
    "fig3.tight_layout()\n",
    "# fig3.savefig('60hr_m'+str(m)+'.png', dpi=300)\n",
    "\n",
    "fig4, ax4 = plt.subplots(1,1)\n",
    "m = 3\n",
    "ax4.plot(print_df.index.values, print_df['m'+str(m)], '.')\n",
    "ax4.set_ylabel('$m_'+str(m)+'$ (Hz)', fontdict={'size':12, 'family':'serif'})\n",
    "plt_unix_time_to_CST(ax4)\n",
    "fig4.set_size_inches(6,3)\n",
    "fig4.tight_layout()\n",
    "# fig4.savefig('60hr_m'+str(m)+'.png', dpi=300)\n",
    "\n",
    "fig5, ax5 = plt.subplots(1,1)\n",
    "m = 4\n",
    "ax5.plot(print_df.index.values, print_df['m'+str(m)], '.')\n",
    "ax5.set_ylabel('$m_'+str(m)+'$ (Hz)', fontdict={'size':12, 'family':'serif'})\n",
    "plt_unix_time_to_CST(ax5)\n",
    "fig5.set_size_inches(6,3)\n",
    "fig5.tight_layout()\n",
    "# fig5.savefig('60hr_m'+str(m)+'.png', dpi=300)\n",
    "\n",
    "fig6, ax6 = plt.subplots(1,1)\n",
    "m = 5\n",
    "ax6.plot(print_df.index.values, print_df['m'+str(m)], '.')\n",
    "ax6.set_ylabel('$m_'+str(m)+'$ (Hz)', fontdict={'size':12, 'family':'serif'})\n",
    "plt_unix_time_to_CST(ax6)\n",
    "fig6.set_size_inches(6,3)\n",
    "fig6.tight_layout()\n",
    "# fig6.savefig('60hr_m'+str(m)+'.png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style('darkgrid')\n",
    "\n",
    "fig2, ax2 = plt.subplots(1,1)\n",
    "m = 1\n",
    "ax2.plot(print_df.index.values, print_df['m'+str(m)]/61.79, '.')\n",
    "ax2.set_ylabel('$m_'+str(m)+'$-61.74 MHz (ppm)', fontdict={'size':12, 'family':'serif'})\n",
    "plt_unix_time_to_CST(ax2)\n",
    "fig2.set_size_inches(6,3)\n",
    "fig2.tight_layout()\n",
    "# fig2.savefig('60hr_m'+str(m)+'.png', dpi=300)\n",
    "\n",
    "\n",
    "fig3, ax3 = plt.subplots(1,1)\n",
    "m = 2\n",
    "ax3.plot(print_df.index.values, print_df['m'+str(m)]/61.79, '.')\n",
    "ax3.set_ylabel('$m_'+str(m)+'$ (ppm)', fontdict={'size':12, 'family':'serif'})\n",
    "plt_unix_time_to_CST(ax3)\n",
    "fig3.set_size_inches(6,3)\n",
    "fig3.tight_layout()\n",
    "# fig3.savefig('60hr_m'+str(m)+'.png', dpi=300)\n",
    "\n",
    "fig4, ax4 = plt.subplots(1,1)\n",
    "m = 3\n",
    "ax4.plot(print_df.index.values, print_df['m'+str(m)]/61.79, '.')\n",
    "ax4.set_ylabel('$m_'+str(m)+'$ (ppm)', fontdict={'size':12, 'family':'serif'})\n",
    "plt_unix_time_to_CST(ax4)\n",
    "fig4.set_size_inches(6,3)\n",
    "fig4.tight_layout()\n",
    "# fig4.savefig('60hr_m'+str(m)+'.png', dpi=300)\n",
    "\n",
    "fig5, ax5 = plt.subplots(1,1)\n",
    "m = 4\n",
    "ax5.plot(print_df.index.values, print_df['m'+str(m)]/61.79, '.')\n",
    "ax5.set_ylabel('$m_'+str(m)+'$ (ppm)', fontdict={'size':12, 'family':'serif'})\n",
    "plt_unix_time_to_CST(ax5)\n",
    "fig5.set_size_inches(6,3)\n",
    "fig5.tight_layout()\n",
    "# fig5.savefig('60hr_m'+str(m)+'.png', dpi=300)\n",
    "\n",
    "fig6, ax6 = plt.subplots(1,1)\n",
    "m = 5\n",
    "ax6.plot(print_df.index.values, print_df['m'+str(m)]/61.79, '.')\n",
    "ax6.set_ylabel('$m_'+str(m)+'$ (ppm)', fontdict={'size':12, 'family':'serif'})\n",
    "plt_unix_time_to_CST(ax6)\n",
    "fig6.set_size_inches(6,3)\n",
    "fig6.tight_layout()\n",
    "# fig6.savefig('60hr_m'+str(m)+'.png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig2, ax2 = plt.subplots(1,1)\n",
    "\n",
    "m = 1\n",
    "\n",
    "sns.set_style('darkgrid')\n",
    "\n",
    "ax2.plot(print_df.index.values, print_df['m'+str(m)], '.')\n",
    "ax2.set_ylabel('$m_'+str(m)+'$-61.74 MHz (Hz)', fontdict={'size':12, 'family':'serif'})\n",
    "plt_unix_time_to_CST(ax2)\n",
    "\n",
    "fig2.set_size_inches(6,3)\n",
    "fig2.tight_layout()\n",
    "\n",
    "# fig2.savefig('60hr_m'+str(m)+'.png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time and azimuthal averaging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in ctags and $\\omega_a$ subrun status for time averaging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Read in ctag info\n",
    "\n",
    "subrun_df = pd.read_hdf('old_hdf5/60hr_subrun.h5', key='ctag')\n",
    "usable_subruns_df = subrun_df[subrun_df['ok']==True].copy()\n",
    "\n",
    "### Bin by subrun\n",
    "\n",
    "intervals = []\n",
    "interval_centers = []\n",
    "interval_range = []\n",
    "for ii in range(usable_subruns_df['end_gps'].values.size):\n",
    "    intervals.append(pd.Interval(usable_subruns_df['start_gps'].values[ii],\n",
    "                                 usable_subruns_df['end_gps'].values[ii],\n",
    "                                 closed='both'\n",
    "                                )\n",
    "                    )\n",
    "    interval_centers.append((usable_subruns_df['start_gps'].values[ii] + usable_subruns_df['end_gps'].values[ii])/2)\n",
    "    interval_range.append(usable_subruns_df['end_gps'].values[ii] - usable_subruns_df['start_gps'].values[ii])\n",
    "    \n",
    "intervals = pd.IntervalIndex(intervals)\n",
    "interval_centers = np.array(interval_centers)\n",
    "interval_range = np.array(interval_range)\n",
    "\n",
    "vtm_bin_df = vtm_df.groupby(pd.cut(vtm_df.index, intervals)).mean()\n",
    "vtm_bin_df['bin_range'] = interval_range\n",
    "vtm_bin_df['start_gps'] = usable_subruns_df['start_gps'].values\n",
    "\n",
    "vtm_bin_df = vtm_bin_df.merge(usable_subruns_df[['start_gps', 'ctags']])\n",
    "vtm_bin_df.index = interval_centers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subrun_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1)\n",
    "\n",
    "ax.plot(subrun_df['start_gps'].values, subrun_df['ctags'].values, '.')\n",
    "\n",
    "plt2.plt_unix_time_to_CST(ax)\n",
    "ax.set_ylabel('ctags')\n",
    "\n",
    "fig.set_size_inches(12,6)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time average, weighted by ctags in \"ok\" subruns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stms = ['st'+str(st)+',m'+str(m+1) for st in range(72) for m in range(6)]\n",
    "time_avg_series = vtm_bin_df[stms].multiply(vtm_bin_df['ctags'], axis='index').sum()/vtm_bin_df['ctags'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_avg_series.to_hdf('sample_time_avg.h5', key='60hr')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive azimuthal average, weighted by fixed probe station extent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "azi_avg_series = pd.Series(index = ['m' + str(m) for m in np.arange(6)+1])\n",
    "\n",
    "for m in range(5):\n",
    "    weight = summed_azimuth_1[:, m] + summed_azimuth_2[:, m]\n",
    "    \n",
    "    total_weight = np.nansum(weight)\n",
    "    stm_list = ['st'+str(st)+',m'+str(m+1) for st in np.arange(72)]\n",
    "    azi_avg_series['m'+str(m+1)] = time_avg_series[stm_list].multiply(weight).sum()/total_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## naive 2D integral\n",
    "\n",
    "def _2D_field_map(x,y):  # in mm\n",
    "    \n",
    "    m1 = azi_avg_series[0]\n",
    "    m2 = azi_avg_series[1]\n",
    "    m3 = azi_avg_series[2]\n",
    "    \n",
    "    r = np.sqrt(x**2 + y**2)\n",
    "    phi = np.arctan2(y,x)\n",
    "    \n",
    "    return m1 + m2*r/45*np.cos(phi) + m3*r/45*np.sin(phi)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _2D_average_integrand(x,y):\n",
    "    f = _2D_field_map(x,y)\n",
    "    g = mu_avg._xy_dist(x, y, 1, 19.4, 45.9, -0.17, 13.5)\n",
    "    R = 7112 + x\n",
    "    return R*f*g\n",
    "\n",
    "def _2D_dist_integrand(x,y):\n",
    "    return mu_avg._xy_dist(x, y, 1, 19.4, 45.9, -0.17, 13.5)*(7112 + x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "opts = {'epsrel':1.0e-3}\n",
    "\n",
    "num_short = scipy.integrate.nquad(_2D_average_integrand, [[-60,60],[-60,60]], opts=opts)\n",
    "den_short = scipy.integrate.nquad(_2D_dist_integrand, [[-60,60],[-60,60]], opts=opts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print num_short\n",
    "print den_short\n",
    "\n",
    "print num_short[0]/den_short[0]/61.79"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (azi_avg_series[0] + 19.4/45 * azi_avg_series[1] - 0.17/45 *azi_avg_series[2])/61.79"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analytic form for field  (through m3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st_phis = np.array(trfp.STATION_BARCODE_PHI)\n",
    "st_phis[0:3] -= 360\n",
    "\n",
    "st_phis = np.append(st_phis, [st_phis[0]+360])\n",
    "print st_phis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st_phis = np.array(trfp.STATION_BARCODE_PHI)\n",
    "st_phis[0:3] -= 360\n",
    "st_phis = np.append(st_phis, [st_phis[0]+360])\n",
    "st_phis = st_phis/180*pi\n",
    "\n",
    "stms = ['st'+str(st)+',m1' for st in range(72)]\n",
    "m1s = np.append(time_avg_series[stms].values,time_avg_series[stms].values[0])\n",
    "\n",
    "stms = ['st'+str(st)+',m2' for st in range(72)]\n",
    "m2s = np.append(time_avg_series[stms].values,time_avg_series[stms].values[0])\n",
    "\n",
    "stms = ['st'+str(st)+',m3' for st in range(72)]\n",
    "m3s = np.append(time_avg_series[stms].values,time_avg_series[stms].values[0])\n",
    "\n",
    "def _xy_field(x, y, m1, m2, m3):  # assume inputs are in mm, fields in Hz\n",
    "    \n",
    "    r = np.sqrt(x**2 + y**2)\n",
    "    phi = np.arctan2(y,x)\n",
    "    \n",
    "    return m1 + m2*r/45*np.cos(phi) + m3*r/45*np.sin(phi)\n",
    "\n",
    "_m1 = scipy.interpolate.CubicSpline(st_phis, m1s, bc_type='periodic')\n",
    "_m2 = scipy.interpolate.CubicSpline(st_phis, m2s, bc_type='periodic')\n",
    "_m3 = scipy.interpolate.CubicSpline(st_phis, m3s, bc_type='periodic')\n",
    "\n",
    "def _field_map(x, y, theta):  # inputs are in mm and radians\n",
    "    m1 = _m1(theta)\n",
    "    m2 = _m2(theta)\n",
    "    m3 = _m3(theta)\n",
    "    return _xy_field(x, y, m1, m2, m3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_field_map(2,2,180)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_field_map(20,20,pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pi = np.pi\n",
    "\n",
    "def average_integrand(x, y, theta):  # takes x, y in mm, theta in rad    \n",
    "    return _field_map(x, y, theta) * mu_avg._xyz_integrand(x, y, theta, 1)\n",
    "\n",
    "def dist_integrand(x, y, theta): # takes x, y in mm, theta in rad\n",
    "    return mu_avg._xyz_integrand(x, y, theta, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "## took ~1 minute\n",
    "opts = {'epsrel':1.0e-6}\n",
    "numerator = scipy.integrate.nquad(_field_map, [[-60.,60.],[-60.,60.],[0,2*pi]], opts=opts)\n",
    "\n",
    "print numerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "## took\n",
    "opts = {'epsrel':1.0e-3}\n",
    "numerator2 = scipy.integrate.nquad(average_integrand, [[-60,60],[-60,60],[0,2*pi]], opts=opts)\n",
    "\n",
    "print numerator2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "## took ~15 minutes\n",
    "opts = {'epsrel':1.0e-6}\n",
    "numerator = scipy.integrate.nquad(average_integrand, [[-60,60],[-60,60],[0,2*pi]], opts=opts)\n",
    "\n",
    "print numerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "## took ~10 sec\n",
    "denominator = scipy.integrate.nquad(dist_integrand, [[-60.,60.],[-60.,60.],[0,2*pi]])\n",
    "\n",
    "print denominator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (numerator[0]/denominator[0])/61.79"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "## takes ~10 seconds\n",
    "\n",
    "print scipy.integrate.nquad(mu_avg._xyz_integrand, [[-60,60],[-60,60],[0,2*np.pi]], args=[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Legacy code/studies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Alan studies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import allantools\n",
    "\n",
    "fig, ax = plt.subplots(1,1)\n",
    "for st in range(7):\n",
    "    stm = 'st'+str(st)+',m1'\n",
    "    tau, adev, _, _ = allantools.mdev(fp_moment_df[stm].values/61.79, data_type='freq', taus='decade')\n",
    "    plt.loglog(tau, adev, '.', label=stm)\n",
    "plt.legend()\n",
    "fig.set_size_inches(12,8)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Sync Offsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sync_offsets, delta_t = helper.sync_offset_calc(tr_corr_df_1, tr_corr_df_2)\n",
    "\n",
    "def gaussian(x, A, x0, sigma): return A*np.exp(-(x-x0)**2/2./sigma**2)\n",
    "\n",
    "fig, axs = plt.subplots(2,3)\n",
    "for i in range(2):\n",
    "    for j in range(3):\n",
    "        st = 3*i+j\n",
    "        if st == 5: continue\n",
    "            \n",
    "        plt.sca(axs[i,j])\n",
    "        hist, bins, _ = plt.hist(sync_offsets[:,st], bins=50)\n",
    "        low, high = axs[i,j].get_xlim()\n",
    "                \n",
    "        bins = bins[0:-1] + 0.5*(bins[1]-bins[0])\n",
    "        coeffs, _ = curve_fit(gaussian, bins, hist, p0=[1., 0., 10.])\n",
    "        fit = gaussian(np.arange(low, high, 0.1), coeffs[0], coeffs[1], coeffs[2])\n",
    "        plt.plot(np.arange(low,high,0.1), fit, label=r'$\\omega_0$ = '+str(np.round(coeffs[1],1))+'\\n$\\sigma$ = '+str(np.round(coeffs[2],1)))\n",
    "        plt.legend(loc=1)\n",
    "        plt2.plt_set_labels(axs[i,j], 'sync offset (Hz)', '', 'm '+str(st+1))\n",
    "        \n",
    "        if st == 0: plt.xlim(-100,100)\n",
    "        else: plt.xlim(-50,50)\n",
    "\n",
    "\n",
    "fig.set_size_inches(12,8)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Extended trolley averages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# calculate extended trolley averages\n",
    "\n",
    "print np.sum(tr_baseline_1*summed_azimuth_1, axis=0)/360\n",
    "\n",
    "print '\\n'\n",
    "\n",
    "print np.sum(tr_baseline_2*summed_azimuth_2, axis=0)/360"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Legacy time/azimuthal averaging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Bin into the agreed upon bins\n",
    "\n",
    "bins = np.arange(1524384055, 1524641055, 1000)-500  # bin edges\n",
    "bin_centers = np.arange(1524384055, 1524640055, 1000)\n",
    "\n",
    "vtm_bin_df = vtm_df.groupby(pd.cut(vtm_df.index, bins)).mean()\n",
    "vtm_bin_df.index = bin_centers\n",
    "\n",
    "test_df = vtm_bin_df.copy()\n",
    "\n",
    "azi_avg_df = pd.DataFrame(np.zeros((test_df.shape[0],6)),\n",
    "                         index = test_df.index,\n",
    "                         columns = ['m' + str(m) for m in np.arange(6)+1])\n",
    "\n",
    "for m in range(5):\n",
    "    weight = summed_azimuth_1[:, m] + summed_azimuth_2[:, m]\n",
    "    \n",
    "    # de-weight station 5 (split into 4 and 6 by distance to each)\n",
    "    weight[4] += weight[5] * (trfp.STATION_BARCODE_PHI[6]-trfp.STATION_BARCODE_PHI[5])/(trfp.STATION_BARCODE_PHI[6]-trfp.STATION_BARCODE_PHI[4])\n",
    "    weight[6] += weight[5] * (trfp.STATION_BARCODE_PHI[5]-trfp.STATION_BARCODE_PHI[4])/(trfp.STATION_BARCODE_PHI[6]-trfp.STATION_BARCODE_PHI[4])\n",
    "    weight[5] = 0\n",
    "    \n",
    "    total_weight = np.nansum(weight)\n",
    "    stm_list = ['st'+str(st)+',m'+str(m+1) for st in np.arange(72)]\n",
    "    azi_avg_df['m'+str(m+1)] = test_df[stm_list].multiply(weight).sum(axis=1)/total_weight\n",
    "    \n",
    "print_df = azi_avg_df[['m1','m2','m3','m5']].copy()/61.79\n",
    "print_df['m1_err'] = 0.116\n",
    "print_df['m2_err'] = 0.06\n",
    "print_df['m3_err'] = 0.06\n",
    "print_df['m5_err'] = 0.1\n",
    "\n",
    "print_df = print_df.sort_index(axis='columns')\n",
    "# print_df.head()\n",
    "# print_df.to_csv('purcell_60hr_7-31.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print print_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print all stations\n",
    "\n",
    "fig, axs = plt.subplots(24,3)\n",
    "\n",
    "for i in range(24):\n",
    "    for j in range(3):\n",
    "        plt.sca(axs[i,j])\n",
    "        st = i*3 + j\n",
    "        plt.plot(vtm_bin_df.index.values, vtm_bin_df['st'+str(st)+',m5']/61.79, '.', markersize=1, color='navy')\n",
    "        plt2.plt_set_labels(axs[i,j], '', 'NS (ppm)', 'st '+str(st))\n",
    "        plt2.plt_unix_time_to_CST(axs[i,j])\n",
    "\n",
    "fig.set_size_inches(16, 80)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Compare with Rachel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "rachel_m1 = np.loadtxt('rachel_m1_st135.txt')\n",
    "\n",
    "fig, axs = plt.subplots(24,3)\n",
    "\n",
    "for i in range(24):\n",
    "    for j in range(3):\n",
    "        plt.sca(axs[i,j])\n",
    "        st = i*3 + j\n",
    "#         if st == 71: continue\n",
    "        plt.plot(vtm_bin_df.index.values, vtm_bin_df['st'+str(st)+',m1']/61.79 - rachel_m1[:,st], '.', markersize=1, color='navy')\n",
    "        plt2.plt_set_labels(axs[i,j], '', 'Dipole (ppm)', 'st '+str(st))\n",
    "        plt2.plt_unix_time_to_CST(axs[i,j])\n",
    "\n",
    "fig.set_size_inches(16, 80)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
