{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to JupyROOT 6.12/04\n"
     ]
    }
   ],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.optimize\n",
    "\n",
    "from datetime import datetime\n",
    "import pytz\n",
    "\n",
    "import gm2\n",
    "import trfp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending fixed probe runs.\n",
      "Appending run 3994.                              \n",
      "Blinding fixed probe runs.\n",
      "\n",
      "Appending trolley runs.\n",
      "Appending run 3998.  \n",
      "Blinding trolley runs.\n",
      "\n",
      "Done appending runs.\n",
      "\n",
      "Subtracting fixed probe baselines.\n",
      "stm: st71,m4.   \n",
      "\n",
      "Applying Jacobian.\n",
      "stm: st71,m4.        \n",
      "\n",
      "Adding trolley baselines.\n",
      "stm: st71,m4.   \n",
      "\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "# Blind trolley and fixed probe separately, but blind all fixed probe stations the same\n",
    "# Blind dipole by order 1 ppm = 61.79 Hz\n",
    "# Blind higher moments by order 100 ppb = 6.179 Hz\n",
    "tr_blinds = np.zeros(17)\n",
    "tr_blinds[0] = np.random.uniform(-61.79, 61.79)\n",
    "tr_blinds[1:] = np.random.uniform(-6.179, 6.179, 16)\n",
    "fp_blinds = np.zeros(6)\n",
    "fp_blinds[0] = np.random.uniform(-61.79, 61.79)\n",
    "fp_blinds[1:] = np.random.uniform(-6.179, 6.179, 5)\n",
    "\n",
    "def blind_tr_moment_df(moment_df, fp_blinds, tr_blinds):\n",
    "    out_df = moment_df.copy()\n",
    "    out_df['tr,m1'] = moment_df['tr,m1'] + tr_blinds[0]\n",
    "    for st in np.arange(72):\n",
    "        stm = 'st' + str(st) + ',m1'\n",
    "        out_df[stm] = moment_df[stm] + fp_blinds[0]\n",
    "    for m in np.arange(2,7):\n",
    "        trm = 'tr,m' + str(m)\n",
    "        out_df[trm] = moment_df[trm] + tr_blinds[m-1]\n",
    "        for st in np.arange(72):\n",
    "            stm = 'st' + str(st) + ',m' + str(m)\n",
    "            out_df[stm] = moment_df[stm] + fp_blinds[m-1]\n",
    "\n",
    "    # Blind higher order trolley moments by order 100 ppb = 6.179 Hz\n",
    "    for m in np.arange(7,18):\n",
    "        trm = 'tr,m' + str(m)\n",
    "        out_df[trm] = moment_df[trm] + tr_blinds[m-1]\n",
    "        \n",
    "    return out_df\n",
    "\n",
    "def blind_fp_moment_df(moment_df, fp_blinds):\n",
    "    # Blind trolley and fixed probe separately, but blind all fixed probe stations the same\n",
    "    # Blind dipole by order 1 ppm = 61.79 Hz\n",
    "    out_df = moment_df.copy()\n",
    "    for st in np.arange(72):\n",
    "        stm = 'st' + str(st) + ',m1'\n",
    "        out_df[stm] = moment_df[stm] + fp_blinds[0]\n",
    "    \n",
    "    # Blind quads, sexts, m6 by order 100 ppb = 6.179 Hz\n",
    "    for m in np.arange(2,7):\n",
    "        for st in np.arange(72):\n",
    "            stm = 'st' + str(st) + ',m' + str(m)\n",
    "            out_df[stm] = moment_df[stm] + fp_blinds[m-1]\n",
    "        \n",
    "    return out_df\n",
    "\n",
    "station_phi = trfp.STATION_BARCODE_PHI\n",
    "station_edges = trfp.STATION_BARCODE_EDGES\n",
    "\n",
    "corrected_df_1 = pd.read_hdf('60hr_trolley_runs_1.h5', key='run_3956_corrected_df')\n",
    "corrected_df_1 = blind_tr_moment_df(corrected_df_1, fp_blinds, tr_blinds)\n",
    "tr_baseline_1, fp_baseline_1, baseline_time_1, summed_azimuth_1, _ = trfp.trolley_run_station_average(corrected_df_1)\n",
    "\n",
    "corrected_df_2 = pd.read_hdf('60hr_trolley_runs_2.h5', key='run_3997_corrected_df')\n",
    "corrected_df_2 = blind_tr_moment_df(corrected_df_2, fp_blinds, tr_blinds)\n",
    "tr_baseline_2, fp_baseline_2, baseline_time_2, summed_azimuth_2, _ = trfp.trolley_run_station_average(corrected_df_2)\n",
    "\n",
    "# load all fixed probe runs moment_df into one big moment_df (runs 3959--3994)\n",
    "print 'Appending fixed probe runs.'\n",
    "fp_moment_df = pd.read_hdf('60hr_fixed_probe_runs.h5', key='run_3959_moment_df')\n",
    "pts = fp_moment_df.shape[0]\n",
    "for run in np.arange(3959, 3995):\n",
    "    temp_df = pd.read_hdf('60hr_fixed_probe_runs.h5', key='run_'+str(run)+'_moment_df')\n",
    "    pts = pts + temp_df.shape[0]\n",
    "    print '\\rAppending run ' + str(run) + '.',\n",
    "    fp_moment_df = fp_moment_df.append(temp_df)\n",
    "    \n",
    "print '\\nBlinding fixed probe runs.'\n",
    "fp_moment_df = blind_fp_moment_df(fp_moment_df, fp_blinds)\n",
    "\n",
    "# load all the trolley runs corrected_df into on big file (to show window of 60hr set) ()\n",
    "print '\\nAppending trolley runs.'\n",
    "tr_corrected_df = pd.read_hdf('60hr_trolley_runs_1.h5', key='run_3955_corrected_df')\n",
    "for run in np.arange(3956, 3959):\n",
    "    temp_df = pd.read_hdf('60hr_trolley_runs_1.h5', key='run_'+str(run)+'_corrected_df')\n",
    "    pts = pts + temp_df.shape[0]\n",
    "    print '\\rAppending run ' + str(run) + '.',\n",
    "    tr_corrected_df = tr_corrected_df.append(temp_df)\n",
    "for run in np.arange(3995, 3999):\n",
    "    temp_df = pd.read_hdf('60hr_trolley_runs_2.h5', key='run_'+str(run)+'_corrected_df')\n",
    "    pts = pts + temp_df.shape[0]\n",
    "    print '\\rAppending run ' + str(run) + '.',\n",
    "    tr_corrected_df = tr_corrected_df.append(temp_df)\n",
    "\n",
    "print '\\nBlinding trolley runs.'\n",
    "tr_corrected_df = blind_tr_moment_df(tr_corrected_df, fp_blinds, tr_blinds)\n",
    "\n",
    "print '\\nDone appending runs.'\n",
    "\n",
    "### Apply baseline corrections, generate virtual trolley measurements\n",
    "\n",
    "fp_moment_baseline = fp_moment_df.copy()\n",
    "fp_moment_tr_run_baseline = tr_corrected_df.copy()\n",
    "\n",
    "# apply baseline corrections to each fp stm\n",
    "print \"\\nSubtracting fixed probe baselines.\"\n",
    "for st in np.arange(72):\n",
    "    num_probes = len(trfp.STATION_PROBE_ID[st])\n",
    "    for m in np.arange(num_probes):\n",
    "        stm = 'st'+str(st)+',m'+str(m+1)\n",
    "        \n",
    "        def backwards_correction(time):\n",
    "            c1 = fp_baseline_1[st, m]\n",
    "            c2 = fp_baseline_2[st, m]\n",
    "            t1 = baseline_time_1[st]\n",
    "            t2 = baseline_time_2[st]\n",
    "            return (c2-c1)/(t2-t1)*(time-t1) + c1\n",
    "        \n",
    "        correction = backwards_correction(fp_moment_baseline.index.values)\n",
    "        fp_moment_baseline[stm] = fp_moment_baseline[stm] - correction\n",
    "        correction = backwards_correction(fp_moment_tr_run_baseline.index.values)\n",
    "        fp_moment_tr_run_baseline[stm] = fp_moment_tr_run_baseline[stm] - correction\n",
    "        \n",
    "        print '\\rstm: ' + stm + '.',\n",
    "        \n",
    "# replace columns in vtr with Jacobian-fixed columns from fp baseline correction\n",
    "\n",
    "print \"\\n\\nApplying Jacobian.\"\n",
    "vtr_df = fp_moment_df.copy()\n",
    "vtr_tr_run_df = tr_corrected_df.copy()\n",
    "\n",
    "for st in np.arange(72):\n",
    "    num_probes = len(trfp.STATION_PROBE_ID[st])\n",
    "    if num_probes == 4:\n",
    "        num_moments = 4\n",
    "        if st == 41:\n",
    "            J = trfp.J_4_PROBE_ST41\n",
    "        elif st == 37 | st == 39:\n",
    "            J = trfp.J_4_PROBE_ST37_ST39\n",
    "        else:\n",
    "            J = trfp.J_4_PROBE\n",
    "    else:\n",
    "        num_moments = 5\n",
    "        if st < 7:\n",
    "            J = trfp.J_6_PROBE_OFFSET\n",
    "        else:\n",
    "            J = trfp.J_6_PROBE\n",
    "    # run over each vtr moment:\n",
    "    for m in np.arange(num_moments):\n",
    "        vtr_stm = 'st'+str(st)+',m'+str(m+1)\n",
    "        fp_stm = ['st'+str(st)+',m'+str(fp_m+1) for fp_m in np.arange(num_moments)]\n",
    "        vtr_df[vtr_stm] = fp_moment_baseline[fp_stm].dot(J[m])\n",
    "        vtr_tr_run_df[vtr_stm] = fp_moment_tr_run_baseline[fp_stm].dot(J[m])\n",
    "        \n",
    "        print '\\rstm: ' + stm + '.',\n",
    "        \n",
    "# Add trolley baseline correction (with backwards correction)\n",
    "print \"\\n\\nAdding trolley baselines.\"\n",
    "\n",
    "for st in np.arange(72):\n",
    "    num_probes = len(trfp.STATION_PROBE_ID[st])\n",
    "    for m in np.arange(num_probes):\n",
    "        stm = 'st'+str(st)+',m'+str(m+1)\n",
    "        \n",
    "        def backwards_correction(time):\n",
    "            c1 = tr_baseline_1[st, m]\n",
    "            c2 = tr_baseline_2[st, m]\n",
    "            t1 = baseline_time_1[st]\n",
    "            t2 = baseline_time_2[st]\n",
    "            return (c2-c1)/(t2-t1)*(time-t1) + c1\n",
    "        \n",
    "        correction = backwards_correction(vtr_df.index.values)\n",
    "        vtr_df[stm] = vtr_df[stm] + correction\n",
    "        correction = backwards_correction(vtr_tr_run_df.index.values)\n",
    "        vtr_tr_run_df[stm] = vtr_tr_run_df[stm] + correction\n",
    "        \n",
    "        print '\\rstm: ' + stm + '.',\n",
    "\n",
    "print '\\n\\nDone.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  st0,m1      st0,m2     st0,m3     st0,m4     st0,m5  \\\n",
      "1524383560  51387.934494  102.257620 -99.983759 -34.886332  19.649595   \n",
      "1524640830  51685.966226  117.162039 -88.144625 -30.440722   4.799612   \n",
      "\n",
      "                st0,m6        st1,m1      st1,m2     st1,m3      st1,m4  \\\n",
      "1524383560 -840.135420  50538.854772  111.497681  61.863677  377.199355   \n",
      "1524640830 -849.729965  50707.914760   73.247228  61.892301  390.237439   \n",
      "\n",
      "             ...       st70,m3    st70,m4    st70,m5     st70,m6  \\\n",
      "1524383560   ...    -31.188585 -34.074374 -76.589752  549.439287   \n",
      "1524640830   ...    -18.966847 -31.820435 -80.794836  550.602669   \n",
      "\n",
      "                 st71,m1    st71,m2    st71,m3    st71,m4  st71,m5  st71,m6  \n",
      "1524383560  51366.648972  60.701032 -42.875926  60.407979      NaN      NaN  \n",
      "1524640830  51645.865840  71.785192 -34.941434  64.150779      NaN      NaN  \n",
      "\n",
      "[2 rows x 432 columns]\n",
      "(25728, 432)\n",
      "(25728,)\n"
     ]
    }
   ],
   "source": [
    "# bin into the agreed upon bins\n",
    "\n",
    "bins = np.arange(1524383560, 1524640850, 10)-5\n",
    "bin_centers = np.arange(1524383560, 1524640840, 10)\n",
    "\n",
    "vtr_time_bin_df = vtr_df.groupby(pd.cut(vtr_df.index,bins)).mean()\n",
    "vtr_time_bin_df.index = bin_centers\n",
    "\n",
    "# print vtr_time_bin_df.iloc[[0,-1]]\n",
    "# print vtr_time_bin_df.shape\n",
    "# print bin_centers.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = vtr_time_bin_df.copy()\n",
    "\n",
    "azi_avg_df = pd.DataFrame(np.zeros((test_df.shape[0],6)),\n",
    "                         index = test_df.index,\n",
    "                         columns = ['m' + str(m) for m in np.arange(6)+1])\n",
    "\n",
    "weight = summed_azimuth_1+summed_azimuth_2\n",
    "total_weight = np.sum(summed_azimuth_1 + summed_azimuth_2)\n",
    "\n",
    "for m in np.arange(6):\n",
    "    stm_list = ['st'+str(st)+',m'+str(m+1) for st in np.arange(72)]\n",
    "    azi_avg_df['m'+str(m+1)] = test_df[stm_list].multiply(weight).sum(axis=1)/total_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    m1  m1_unc        m2  m2_unc        m3  m3_unc        m5  \\\n",
      "1524383560  840.945542   0.116  0.181946    0.06  0.075832   0.062 -0.827792   \n",
      "1524383570  840.924363   0.116  0.182149    0.06  0.068415   0.062 -0.837025   \n",
      "1524383580  840.908940   0.116  0.164082    0.06  0.065106   0.062 -0.845231   \n",
      "1524383590  840.879869   0.116  0.137257    0.06  0.064849   0.062 -0.861169   \n",
      "1524383600  841.015544   0.116  0.177587    0.06  0.066285   0.062 -0.816883   \n",
      "\n",
      "            m5_unc  \n",
      "1524383560     0.1  \n",
      "1524383570     0.1  \n",
      "1524383580     0.1  \n",
      "1524383590     0.1  \n",
      "1524383600     0.1  \n"
     ]
    }
   ],
   "source": [
    "review_df = azi_avg_df[['m1', 'm2', 'm3', 'm5']].copy()\n",
    "\n",
    "review_df['m1_unc'] = 0.116\n",
    "review_df['m2_unc'] = 0.060\n",
    "review_df['m3_unc'] = 0.062\n",
    "review_df['m5_unc'] = 0.100\n",
    "\n",
    "review_df['m1'] = review_df['m1']/61.79\n",
    "review_df['m2'] = review_df['m2']/61.79\n",
    "review_df['m3'] = review_df['m3']/61.79\n",
    "review_df['m5'] = review_df['m5']/61.79\n",
    "\n",
    "review_df = review_df.reindex(sorted(review_df.columns), axis=1)\n",
    "\n",
    "print review_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_df.to_csv('purcell_60hr.dat', sep=' ', index_label='time', float_format='%0.4f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
