{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.backends.backend_pdf as backend_pdf\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.optimize\n",
    "\n",
    "from datetime import datetime\n",
    "import pytz\n",
    "\n",
    "import gm2\n",
    "import trfp\n",
    "\n",
    "sns.set_style('darkgrid')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need a list of \"good stations\" to use in the averaging to replace data in the affected stations\n",
    "trolley_moment_df = pd.read_hdf('60hr_trolley_runs_1.h5', key='run_3956_moment_df')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_by_nan(input_array):\n",
    "    return [input_array[clump] for clump in np.ma.clump_unmasked(np.ma.masked_invalid(input_array))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "barcode = trfp.STATION_BARCODE_PHI\n",
    "nomask_df = trolley_moment_df.copy()\n",
    "mask_df = nomask_df.copy()\n",
    "temp_avg_df = pd.DataFrame(index=mask_df.index)\n",
    "\n",
    "veto_extent = 25\n",
    "split_station = []\n",
    "all_good_stations = np.arange(6,72)  # not using the inflector stations\n",
    "no_ground_loop_stations = np.array(range(6,16)+range(64,72))  # vaid for 25 deg veto\n",
    "\n",
    "# first need to mask when trolley is near each station\n",
    "for st in range(72):\n",
    "    stms = ['st' + str(st) + ',m' + str(m+1) for m in range(6)]\n",
    "\n",
    "    veto_low = (barcode[st]-(veto_extent-3)/2)%360\n",
    "    veto_high = (barcode[st]+3+(veto_extent-3)/2)%360\n",
    "\n",
    "    if veto_low < veto_high:\n",
    "        mask = (nomask_df['tr_phi']>veto_low) & (nomask_df['tr_phi']<veto_high)\n",
    "    else:  # this happens when wrapping around 360 deg\n",
    "        mask = (nomask_df['tr_phi']>veto_low) | (nomask_df['tr_phi']<veto_high)\n",
    "\n",
    "    if mask.iloc[0] & mask.iloc[-1]: split_station += [True]\n",
    "    else: split_station += [False]\n",
    "\n",
    "    mask_df[stms] = nomask_df[stms].mask(mask)\n",
    "    \n",
    "    # next need to average all good stations that are not within 3 of current station\n",
    "    if st not in range(16, 23):  # note that these ranged were chosen for 25 deg veto\n",
    "        averaging_stations = np.delete(all_good_stations,\n",
    "                                       np.argwhere((np.abs((all_good_stations - st)%72)<=3)\n",
    "                                                  | (np.abs((all_good_stations - st)%72)>=69))\n",
    "                                      )\n",
    "    else:\n",
    "        averaging_stations = np.delete(no_ground_loop_stations,\n",
    "                                       np.argwhere((np.abs((no_ground_loop_stations - st)%72)<=3)\n",
    "                                                  | (np.abs((no_ground_loop_stations - st)%72)>=69))\n",
    "                                      )\n",
    "    for m in range(6):  # this will need to go over all moments\n",
    "        stm = 'st' + str(st) + ',m' + str(m+1)\n",
    "        avg_stms = ['st'+str(avg_st)+',m'+str(m+1) for avg_st in averaging_stations]\n",
    "        temp_avg_df[stm] = nomask_df[avg_stms].mean(axis=1).mask(~mask)\n",
    "\n",
    "replaced_df = mask_df.copy()\n",
    "\n",
    "\n",
    "# next need to remove the ring wide drift and replace with the station drift\n",
    "for st in range(72):\n",
    "    num_moments = len(trfp.STATION_PROBE_ID[st])\n",
    "    for m in range(num_moments):\n",
    "        stm = 'st' + str(st) + ',m' + str(m+1)\n",
    "        num_endpts = 5\n",
    "        if not split_station[st]:\n",
    "\n",
    "            inner_splits = split_by_nan(temp_avg_df[stm].values)\n",
    "            outer_splits = split_by_nan(mask_df[stm].values)\n",
    "            first_inner_avg = np.mean(inner_splits[0][0:num_endpts])\n",
    "            last_inner_avg = np.mean(inner_splits[0][-num_endpts:])\n",
    "            first_outer_avg = np.mean(outer_splits[0][-num_endpts:])\n",
    "            last_outer_avg = np.mean(outer_splits[1][0:num_endpts])  # these all use 5 values to make extrapolation easier\n",
    "\n",
    "            inner_delta_y = 0.5 * (last_inner_avg-first_inner_avg)/inner_splits[0].size * (num_endpts-1)\n",
    "            outer_delta_y = 0.5 * (last_outer_avg-first_outer_avg)/inner_splits[0].size * (num_endpts-1)\n",
    "            inner_lin_fit = np.linspace(first_inner_avg-inner_delta_y, last_inner_avg+inner_delta_y, num=inner_splits[0].size)\n",
    "            outer_lin_fit = np.linspace(first_outer_avg+outer_delta_y, last_outer_avg-outer_delta_y, num=inner_splits[0].size)\n",
    "\n",
    "            replacement_values = inner_splits[0] - inner_lin_fit + outer_lin_fit\n",
    "            replaced_df[stm][replaced_df[stm].isna()] = np.array(replacement_values)\n",
    "\n",
    "        else:\n",
    "\n",
    "            inner_splits = split_by_nan(temp_avg_df[stm].values)\n",
    "            first_inner_avg = [np.mean(inner_splits[0][0:num_endpts]), np.mean(inner_splits[1][0:num_endpts])]\n",
    "            last_inner_avg = [np.mean(inner_splits[0][-num_endpts:]), np.mean(inner_splits[1][-num_endpts:])]\n",
    "            inner_delta_y = [0.5 * (last_inner_avg[0]-first_inner_avg[0])/inner_splits[0].size * (num_endpts-1),\n",
    "                             0.5 * (last_inner_avg[1]-first_inner_avg[1])/inner_splits[1].size * (num_endpts-1)]\n",
    "\n",
    "            first_inner_fit = np.linspace(first_inner_avg[0]-inner_delta_y[0],\n",
    "                                          last_inner_avg[0]+inner_delta_y[0],\n",
    "                                          num=inner_splits[0].size)\n",
    "            second_inner_fit = np.linspace(first_inner_avg[1]-inner_delta_y[1],\n",
    "                                          last_inner_avg[1]+inner_delta_y[1],\n",
    "                                          num=inner_splits[1].size)\n",
    "\n",
    "            # use 260 seconds of data after (or before) the vetoed window to make a linear fit to approximate \"station drift\"\n",
    "            outer_splits = split_by_nan(mask_df[stm].values)\n",
    "            dt = 1  # the time step, usually 1 sec, but might as well make it a variable\n",
    "            num_pts = 260//dt  # integer period of 130 sec signal\n",
    "            first_outer_fit_coeffs = np.polyfit(np.arange(num_pts)*dt, outer_splits[0][0:num_pts], deg=1)\n",
    "            second_outer_fit_coeffs = np.polyfit(np.arange(num_pts)*dt, outer_splits[0][-num_pts:], deg=1)\n",
    "            first_outer_fit = np.polyval(first_outer_fit_coeffs,\n",
    "                                         np.linspace(inner_splits[0].size*-dt, -dt, num=inner_splits[0].size)\n",
    "                                        )\n",
    "            second_outer_fit = np.polyval(second_outer_fit_coeffs,\n",
    "                                          np.linspace(num_pts*dt, (num_pts+inner_splits[0].size)*dt,\n",
    "                                                      num=inner_splits[1].size)\n",
    "                                         )\n",
    "\n",
    "            first_replacement_values = inner_splits[0] - first_inner_fit + first_outer_fit\n",
    "            second_replacement_values = inner_splits[1] - second_inner_fit + second_outer_fit\n",
    "            replacement_values = np.append(first_replacement_values, second_replacement_values)\n",
    "            replaced_df[stm][replaced_df[stm].isna()] = np.array(replacement_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf = backend_pdf.PdfPages(\"new_trolley_footprint_replacement_m1_time.pdf\")\n",
    "\n",
    "m = 0\n",
    "\n",
    "# x = nomask_df['tr_phi']\n",
    "x = mask_df.index.values\n",
    "\n",
    "fig,ax=plt.subplots(4,1)\n",
    "\n",
    "for st in range(72):\n",
    "    \n",
    "    for axis in ax:\n",
    "        plt.sca(axis)\n",
    "        plt.cla()\n",
    "\n",
    "    plt.sca(ax[0])\n",
    "    plt.plot(x, nomask_df['st'+str(st)+',m'+str(m+1)], '.')\n",
    "    plt.sca(ax[1])\n",
    "    plt.plot(x, mask_df['st'+str(st)+',m'+str(m+1)], '.')\n",
    "    # plt.plot(x_edges, [first_outer_avg, last_outer_avg], '.', color='orange', markersize=10)\n",
    "    plt.sca(ax[2])\n",
    "    plt.plot(x, temp_avg_df['st'+str(st)+',m'+str(m+1)], '.')\n",
    "    # plt.plot(x_edges, [first_inner_avg, last_inner_avg], '.', color='orange', markersize=10)\n",
    "    plt.sca(ax[3])\n",
    "    plt.plot(x, replaced_df['st'+str(st)+',m'+str(m+1)], '.')\n",
    "\n",
    "    for axis in ax:\n",
    "        axis.set_xlim((np.min(x),np.max(x)))\n",
    "\n",
    "    ax[0].set_title('station ' + str(st) + ', m' + str(m) + ' raw data')\n",
    "    ax[1].set_title('vetoed window')\n",
    "    ax[2].set_title('replacement data from ring avg')\n",
    "    ax[3].set_title('replacement complete')\n",
    "\n",
    "    fig.set_size_inches(12, 12)\n",
    "    fig.tight_layout()\n",
    "    \n",
    "    pdf.savefig(fig, dpi=70)\n",
    "\n",
    "pdf.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
